---
title: "¬øQui√©n sobrevivi√≥ al accidente del Titanic?"
description: "Entreno 20 modelos de Machine Learning para averiguarlo."
author: "Paulo Villarroel"
date: "2022-10-08"
categories: [r, tutorial, machine learning]
image: "titanic.jpg"
---

Bienvendo/a!! üòõ

Hoy vamos a hacer algo distinto. Vamos a tratar de predecir qui√©n sobrevive de los pasajeros del Titanic, usando inteligencia artificial.

Ojo. No voy a ser muy exhaustivo, ni tan profundo en el an√°lisis ni usar√© modelos de machine learning muy complejos, pues quiero que este art√≠culo te sirva como ejemplo de lo que se puede llegar a hacer y sea simple de seguir. En la vida real la cosa es un poco distinta. Generalmente, se realizan m√∫ltiples pruebas con muchos modelos y se van seleccionando en base a su desempe√±o (ya veremos qu√© significa esto). Por otro lado, los datos tienden a estar mucho m√°s sucios y el trabajo de limpieza es una de las actividades a la que m√°s se le dedica tiempo y esfuerzo.

Para efectos de este art√≠culo, usarmos los datos de una competencia de Kaggle, en donde est√° un dataset (un conjunto de datos) sobre los pasajeros del Titanic, en donde se especifican algunas variables y quien sobrevivi√≥ o no. Puedes revisar los datos en [el siguiente enlace](https://www.kaggle.com/competitions/titanic/data).

## Los datos

Como te mencionada, los datos correponden a registros de pasajeros que se subieron en el Titanic. Si, el Titanic. Ese barco brit√°nico que naufrag√≥ en el oc√©ano Atl√°ntico durante la noche del 14 y la madrugada del 15 de abril de 1912, mientras realizaba su viaje inaugural desde Southampton a Nueva York, tras chocar con un iceberg. En el hundimiento la gran mayor√≠a de las personas que iban a bordo, lo que convierte a esta cat√°strofe en uno de los mayores naufragios de la historia.

Hay una pel√≠cula de como 4 horas donde sale Di Caprio, tambi√©n. La viste?

Ok. Ya sabemos de qu√© van los datos.

Los datos incluyen 3 archivos:

-   gender_submission.csv

-   test.csv

-   train.csv

El primero es un ejemplo de c√≥mo se deben subir las predicciones a la web de Kaggle para participar de la competencia (Ah! La competencia tiene que ver con qui√©n logra acertar m√°s con las predicciones).

El archivo test contiene datos de los pasajeros para realizar las pruebas del modelo de machine learning. No contiene datos sobre la sobrevivencia. Son los registros que hay que predecir.

El archivo train contiene los datos de los pasajeros para realizar el entrenamiento del algoritmo de machine learninig. Este tiene especificado si el pasajero sobrevivi√≥ o no.

Vamos con el tema...

Cargamos las librer√≠as:

```{r}
#| warning: false

library(tidyverse)
library(tidymodels)
library(here)
library(skimr)
library(janitor)
```

Cargamos los datos:

```{r}
#| warning: false

here::i_am("index.qmd")
train <- read_csv("train.csv")
test <- read_csv("test.csv")
```

## An√°lisis exploratorio

Esta etapa es fundamental. el an√°lisis exploratorio de datos es una de las primeras etapas en cualquier proyectos de ciencia de datos. El objetivo es analizar los datos para entender c√≥mo est√°n compuestos y qu√© representan. Habitualmente para estos fines, se pueden usar estad√≠sticas descriptivas e inferenciales. Adem√°s, el uso de visualizaciones es un elemento super valioso.

Por lo dem√°s, de este an√°lisis exploratorio, se pueden desprender distintas acciones de **Feature Engeneering**. Este es un paso muy importante en el aprendizaje autom√°tico. El feature engineering (o ingenier√≠a de caracter√≠sticas) se refiere al proceso de dise√±o de caracter√≠sticas artificiales en un algoritmo. Estas caracter√≠sticas artificiales son utilizadas por ese algoritmo para mejorar su rendimiento y precisi√≥n.

Este paso es fundamental en los modelos de machine learning. Aunque para efectos de este art√≠culo, posiblemente no har√© todo lo que se podr√≠a hacer, como expliqu√© al inicio, para privilegiar la comprensi√≥n m√°s que los resultados.

Ya que tenemos los datos, ahora veamos un poco de qu√© se tratan:

```{r}
#| warning: false

str(train)
```

```{r}
#| warning: false

str(test)
```

Puedes notar que los 2 archivos son similares en su composici√≥n, excepto que `train` tiene la variable `Survived` y `test` no. Adem√°s, `train` contiene casi el doble de registros (filas) que `test`.

En Kaggle se explican qu√© significan los variables (diccionario) y ponen algunas notas. Estos datos son importantes para comprender el dataset y pensar en c√≥mo ajustarlos si es necesario. En todo proyecto de datos es muy relevante entender qu√© representan los datos y cu√°les son sus posibilidades.

**Diccionario:**

![](dictionary.png){fig-align="center" width="800"}

**Notas:**

![](dictionary2.png){fig-align="center" width="800"}

Revisemos las primeras filas de los datos:

```{r}
#| warning: false

head(train)
```

```{r}
#| warning: false

head(test)
```

Veamos m√°s cosas de los datos. Usaremos la librer√≠a `skimr` y su funci√≥n `skim` para explorar los datos y generar algunas primeras estad√≠sticas de las variables.

```{r}
#| warning: false

skim(train)
```

```{r}
#| warning: false

skim(test)
```

Con el an√°lisis anterior, nos damos cuenta que hay datos faltantes (missing data) o NA¬¥s. En particular, en la variable `age`, que es la que tiene una gran cantidad de NA¬¥s. Este dato es relevante, pues podr√≠a afectar bastante el algoritmo. Trabajar los datos faltantes es un √°rea muy importante, por lo que no podemos dejar pasar este hecho. Ya abordaremos esto m√°s adelante.

Por ahora, dado que ambos set de datos son muy similares, los voy a unir para dejarlos en solo 1 objeto. Esto me ser√° √∫til para el an√°lisis y feature engineering de todo el conjunto. Luego lo dividir√© nuevamente para efectos del algoritmo.

```{r}
#| warning: false

all_data <- bind_rows(list("train" = train, "test" = test), .id = "id")
```

```{r}
glimpse(all_data)
```

```{r}
#| warning: false

skim(all_data)
```

F√≠jate que hice algo extra al unir los datos. Inclu√≠ una nueva variable `id` en donde se se√±ala si los registros son de `test` o `train`.

Veamos cu√°ntas personas sobrevivieron (de los datos, que son una muestra de todos los pasajeros del Titanic, que eran m√°s de 2200 en total).

```{r}
table(all_data$Survived)
```

Los datos clasificados como 0 no sobrevivieron y los 1; si. Podemos ver la misma tabla, pero en proporci√≥n.

```{r}
round(prop.table(table(all_data$Survived)), 4) * 100
```

Veamos si el sexo nos da alguna informaci√≥n importante.

```{r}
table(all_data$Sex)
```

```{r}
table(all_data$Sex, all_data$Survived)
```

```{r}
#| warning: false

all_data |> 
  filter(!is.na(Survived)) |> 
  mutate(Survived = factor(Survived)) |> 
  group_by(Sex, Survived) |> 
  summarise(n = n()) |> 
  ggplot(aes(Survived, n, fill = Survived)) +
  geom_col(show.legend = FALSE)
```

```{r}
#| warning: false

all_data |> 
  filter(!is.na(Survived)) |> 
  mutate(Survived = factor(Survived)) |> 
  group_by(Sex, Survived) |> 
  summarise(n = n()) |> 
  ggplot(aes(Survived, n, fill = Sex)) +
  geom_col(position = "dodge")
```

```{r}
all_data |> 
  filter(Survived == 1) |> # Si sobreviven
  tabyl(Sex)
```

```{r}
all_data |> 
  filter(Survived == 0) |> # No sobreviven
  tabyl(Sex)
```

```{r}
all_data |> 
  filter(!is.na(Age)) |> 
  group_by(Sex) |> 
  summarise(mean = mean(Age))
```

```{r}
#| warning: false

all_data |> 
  filter(!is.na(Age), !is.na(Survived)) |> 
  group_by(Sex, Survived) |> 
  summarise(mean = mean(Age))
```

```{r}
all_data |> 
  filter(!is.na(Age), !is.na(Survived)) |> 
  ggplot(aes(Age, Sex)) +
  geom_boxplot()
```

```{r}
all_data |> 
  filter(!is.na(Age), !is.na(Survived)) |> 
  ggplot(aes(Age, factor(Survived), fill = Sex)) +
  geom_boxplot()
```

Revisemos algo de los datos las clases:

```{r}
all_data |>
  ggplot(aes(factor(Pclass), fill = factor(Pclass))) +
  geom_bar() +
  scale_fill_discrete(name = "Class", labels = c("1st", "2nd", "3rd"))
```

```{r}
all_data |> 
  filter(!is.na(Survived)) |> 
  ggplot(aes(factor(Pclass), fill = factor(Survived))) +
  geom_bar(position = "dodge")
```

Ac√° aparece algo interesate. Las personas de tercera clase, en su mayor√≠a, no sobrevivieron. A diferencia de los de primera clase, donde hubo m√°s sobrevivientes que fallecidos (proporcionalmente).

Revisemos el costo de los tickets.

```{r}
#| warning: false

all_data |> 
  ggplot(aes(Fare)) + 
  geom_histogram(bins = 30)
```

```{r}
#| warning: false

all_data |> 
  filter(!is.na(Survived)) |> 
  ggplot(aes(Fare, fill = factor(Survived))) + 
  geom_density(alpha = 0.6)
```

Estos datos se√±alan en el mismo sentido de que las personas de clases m√°s altas y con tickets m√°s caros, sobrevivieron m√°s.

## Manejo de NA¬¥s

Volvamos un poco a revisar los datos faltantes (NA¬¥s).

```{r}
#| warning: false

summary(VIM::aggr(all_data))
```

Ya lo hab√≠amos visto antes. Los registros tienen bastantes datos faltantes (missing data). Estos datos se presentan especialmente en las variables Age y Cabin. Survived tienen muchos NA¬¥s, pues unimos los regitros al inicio por temas metodol√≥gicos, pero ac√° no tiene relevancia.

Ac√° tenemos un tema muy relevante en proyectos de datos y es el manejar los datos faltantes y tomar decisiones al respecto. En este art√≠culo no profundizar√© demasiado en este tema, pues se escapa del objetivo de ser m√°s demostrativo. Pero es un √°rea relevante de estudio que posiblemente aborde en otro art√≠culo m√°s adelante.

En este caso, tomar√© 2 decisiones. Con respecto a la variable `Cabin` no la considar√© para el desarrollo y entrenamiento del algoritmo, pues tiene un porcentaje muy alto de p√©rdida y adaptarlo a algo √∫til parece ser poco factible, en un primer momento. Con la variable `Age` pasa algo distinto, pues parece tener m√°s relevancia en la probabilidad de sobrevivir.

Entonces, haremos algo para completar esos datos. Una alternativa es imputar datos. Es decir, asumir la edad en base a algunos supuestos. Existen varias metodolog√≠as como calcular la media o mediana de todos los datos de edad y pon√©rselo a los NA¬¥s. Otro m√©todo es aplicar algoritmos de machine learning para predecir ese dato e imputarlo.

Veamos algunos datos de la edad:

```{r}
summary(all_data$Age)
```

```{r}
#| warning: false

all_data |> 
  ggplot(aes(Age)) +
  geom_histogram()
```

Debido a que la distribuci√≥n de la edad se acerca a una distribuci√≥n normal (histograma) y a que la media y mediana se a cercan bastante, podriamos usar el primer enfoque de amputaci√≥n, que es usar la mediana para completar los datos faltantes. Te recuerdo que este es solo un enfoque posible. En proyectos reales, lo que se hace es probar muchos modelos y m√©todos y analizar su desempe√±o. Insisto, para efectos de este art√≠culo, usar√© este acercamiento.

Verifiquemos las normalidad de los datos de edad. Primero, realizaremos un gr√°fico QQ plot, el cual consiste en comparar los cuantiles de la distribuci√≥n observada con los cuantiles te√≥ricos de una distribuci√≥n normal con la misma media y desviaci√≥n est√°ndar que los datos. En la medida que los datos se ajusten a la l√≠nea proyectada, m√°s se aproximan a una distribuci√≥n normal.

Aplicar√© la funci√≥n `lillie.test` de la librer√≠a `nortest` para usar el test de *Lilliefors*. Este test nace con la idea de resolver uno de los problemas del test *Kolmogorov-Smirnov* que es al no conocer la media y la varianza poblacional, tiene poca potencia estad√≠stica. El test *Lilliefors* asume que la media y varianza son desconocidas y es especialmente √∫til en muestras grandes.

```{r}
qqnorm(all_data$Age, pch = 19, col = "gray50")
qqline(all_data$Age)
```

```{r}
nortest::lillie.test(all_data$Age)
```

Vemos que tanto QQ plot y el test *Lilliefors* apuntan a que los datos tienen una distribuci√≥n normal.

Volvamos a ver los datos, separados por sexo:

```{r}
#| warning: false

all_data |> 
  ggplot(aes(Age)) +
  geom_histogram() +
  facet_grid(~ Sex)
```

**Imputaci√≥n de datos.**

Podr√≠amos imputar los datos faltantes usando las siguientes l√≠neas de c√≥digo.

```{r}
all_data$Age[is.na(all_data$Age)] <- median(all_data$Age, na.rm = TRUE)
all_data$Fare[is.na(all_data$Fare)] <- mean(all_data$Fare, na.rm = TRUE)
all_data$Embarked[is.na(all_data$Embarked)] <- mode(all_data$Embarked)
```

## Feature Engineering

El dataset tiene algunas variables que son de dudosa ayuda para predecir y generar el algoritmo, al menos, a priori. Casi por sentido com√∫n. A√∫n cuando tomar decisiones por sentido com√∫n podr√≠a no ser la mejor alternativa, muchas veces nos equivocamos o traspasamos nuestros sesgos a los an√°lisis. La idea siempre es tratar de dejar que "los datos hablen". En este caso, como es un art√≠culo m√°s referencial, no profundizar√© en la generaci√≥n y manipulaci√≥n de las variables para no confundir tanto, pero si har√© un par de cosas que me parecen interesantes y que muestra las posibilidades del feature engineering.

Las variables `Ticket`, `Name` y `Cabin` parecen ser datos poco informativos para saber si alguien sobrevivi√≥ o no al accidente. Sin embargo, no ser√≠a tan as√≠. Es posible que la cabina tenga alguna relaci√≥n con la sobrevivencia, quiz√°s por cercan√≠a a un pasillo o algo as√≠. El n¬∞ de ticket tambi√©n quiz√°s se asocia a algo, no lo sabemos, es necesario investigar. Que como ya te mencion√©, no lo haremos en esta ocasi√≥n jaja üòÑ

Pero si revisemos un poco m√°s el nombre de los pasajeros. Si revisas, el registro contiene el nombre de la personas y su t√≠tulo (Mr, Miss, Dr, Col, etc). Ese dato podr√≠a ser √∫til para la predicci√≥n. Quiz√°s hab√≠a alg√∫n tipo de jerarqu√≠a que favoreciera que se salvaran. Tambi√©n el apellido de las personas podr√≠a ser √∫til, m√°s que nada por temas de agrupar a familias.

Entonces, crearemos 2 nuevas variables: `Title` y `Surname`. Para ello, usaremos la funci√≥n `mutate` y nos ayudaremos de las REGEX (expresiones regulares) para extraer los datos desde el nombre.

Consejo: aprende REGEX. Es una gran herramienta en el an√°lisis de datos y aplica no solo para programaci√≥n en R, sino que para cualquier otro. Incluso se usa en navegadores web, email y diversas aplicaciones.

```{r}
all_data <- all_data |>
  mutate(
    Title = str_extract(Name, "(?<=,[:space:])(.*?)[.]"),
    Surname = str_extract(Name, ".*(?=[,])")
  )
```

Veamos como nos quedaron los datos...

```{r}
all_data |> 
  head()
```

```{r}
unique(all_data$Title)
```

Podemos ampliar la variable Sex en base a los t√≠tulos. En especial, agregar algo que identifique a los ni√±os. Si te fijaste, los sobrevivientes son en general m√°s j√≥venes. Adem√°s, existe esta frase t√≠pica de salvar a los ni√±os y las mujeres primero. No tengo claro si eso es tan real, pero podr√≠a serlo. As√≠ que agreguemos la posibilidad.

```{r}
Man <- c(
  "Mr.", "Sir.", "Don.", "Rev.", "Major.",
  "Col.", "Capt.", "Jonkheer.",
  "Dr.", "Nobel."
)
Female <- c("Mrs.", "Miss.", "Mme.", "Ms.", "Lady.", "Mlle.", "the Countess.", "Dona.")
Boy <- c("Master.")

all_data <- all_data |>
  rowwise() |>
  mutate(
    Sex =
      case_when(
        (Title %in% Man) ~ "Man",
        (Title %in% Female) ~ "Female",
        (Title %in% Boy) ~ "Boy",
        TRUE ~ Title
      )
  )
```

Revisemos c√≥mo quedan los grupos con esta nueva clasificaci√≥n:

```{r}
#| warning: false

all_data |> 
  filter(!is.na(Survived)) |> 
  tabyl(Sex, Survived)
```

```{r}
#| warning: false

all_data |> 
  filter(!is.na(Survived)) |> 
  mutate(Survived = factor(Survived)) |> 
  group_by(Sex, Survived) |> 
  summarise(n = n()) |> 
  ggplot(aes(Sex, n, fill = Survived)) +
  geom_col(position = "dodge")
```

Ahora vamos a crear una nueva variable, que es el tama√±o de la familia. Para eso, sumaremos las variables `SibSp` (n¬∞ de hermanos y esposas/os) y `Parch` (n¬∞ de hijos y padres). A la suma le agregamos 1, pues agregamos al mismo pasajero al grupo familiar.

```{r}
all_data <- all_data |>
  mutate(
    Family_size = as.numeric(SibSp) + as.numeric(Parch) + 1,
    Family_type = factor(ifelse(Family_size == 1, "Single",
      ifelse(Family_size <= 3, "Small", "Large")
    ))
  ) |> 
  unnest(cols = c())
```

Revisemos nuevamente los datos faltantes. Esto es importante, pues muchos modelos de machine learning no soportan variables con NA¬¥s o pueden alterar las predicciones.

```{r}
#| warning: false

summary(VIM::aggr(all_data))
```

Por ahora, voy a dejar el an√°lisis exploratorio hasta ac√°. Podr√≠amos estar mucho tiempo m√°s revisando y d√°ndole vueltas al tema, pero creo que con lo que hemos visto ya te has hecho una buena idea de qu√© va √©sto.

Habitualmente, los proyecto de Ciencia de Datos destinan cerca del 80% del tiempo en este tipo de actividades.

## Modelamiento ML

Para el modelamiento del algoritmo de machine learning (ML) usaremos la librer√≠a `H2O`.

[H2O](https://h2o.ai/) funciona bastante distinto que otras librer√≠as, pues lo que hace es levantar un servidor y nos conoctamos a √©l, y es en ese servidor donde se ejecutan los algoritmos. H2O es una plataforma de autoML o de modelos de machine learning pre-entrenados. En palabras simples, la configuraci√≥n de los algoritmos viene ya lista "de f√°brica". En palabras m√°s complejas, los modelos de autoML ajustan el tuneo de los hiperpar√°metros de forma autom√°tica o ya cuentan con valores predefinidos.

```{r}
# Separamos el dataset para los datos de entrenamiento
titanic_train <- all_data |>
  filter(id == "train") |>
  select(-c(id, PassengerId, Name, Ticket, Cabin))
```

Analicemos los tipos de datos de `titanic_train`:

```{r}
str(titanic_train)
```

Cambiaremos algunos tipos de datos por algo m√°s √∫til.

```{r}
titanic_train <- titanic_train |>
  mutate(
    Survived = factor(Survived),
    Pclass = factor(Pclass),
    Sex = factor(Sex),
    Embarked = factor(Embarked),
    Title = factor(Title)
  )
```

Ok. Tenemos nuestros datos de entrenamiento listos o, al menos, m√°s preparados para ser analizados.

```{r}
#| warning: false

# Cargamos la librer√≠a de H2O
library(h2o)

# Creaci√≥n de un cluster local con todos los cores disponibles
h2o.init(
  ip = "localhost",
  # -1 indica que se empleen todos los cores disponibles
  nthreads = -1,
  # M√°xima memoria disponible para el cluster
  max_mem_size = "3g"
)

# Se eliminan los datos del cluster por si ya hab√≠a sido iniciado
h2o.removeAll()

# Para que no se muestre la barra de progreso
h2o.no_progress()
```

```{r}
titanic_h2o = as.h2o(titanic_train)
```

Para nuestro caso, aplicaremos autoML o machine learning automatizado.

En la [documentaci√≥n oficial de H2O](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) puedes ver m√°s detalles.

Vamos al tema y veamos c√≥mo se podr√≠a implementar una soluci√≥n simple de autoML.

```{r}
#| warning: false

# Separaci√≥n de las observaciones en conjunto de entrenamiento y test
splits <- h2o.splitFrame(data = titanic_h2o, ratios = 0.8, seed = 123)
titanic_train_h2o <- splits[[1]]
titanic_test_h2o  <- splits[[2]]

# Se define la variable respuesta y los predictores
response <- "Survived"

# Para este modelo se emplean todos los predictores disponibles
predictors  <- setdiff(h2o.colnames(titanic_h2o), response)

# Ejectutamos 20 modelos de autoML
aml <- h2o.automl(
  x = predictors, y = response,
  training_frame = titanic_train_h2o,
  max_models = 20,
  seed = 123
)
```

```{r}
# Ver autoML Leaderboard
lb <- aml@leaderboard
print(lb, n = nrow(lb)) 
```

```{r}
# Podemos revisar el modelo ganador
aml@leader
```

```{r}
# Importancia de las variables
h2o.varimp(aml@leader)
h2o.varimp_plot(aml@leader)
```

```{r}
# √Årea bajo la curva AUC para los datos de entrenamiento
h2o.auc(aml@leader, train = TRUE)
h2o.performance(model = aml@leader, train = TRUE)
```

```{r}
# Performance para datos de validaci√≥n
h2o.auc(aml@leader, xval = TRUE)
```

Revisemos la curva entre **Recall vs Precision**.

Estos 2 indicadores son de gran relevancia en la evaluaci√≥n del desempe√±o de machine learninig. La Precisi√≥n (tambi√©n llamada valor predictivo positivo) es la fracci√≥n de instancias relevantes entre las instancias recuperadas, mientras que el Recall (tambi√©n conocida como sensibilidad) es la fracci√≥n de instancias relevantes que se recuperaron.

![](Precisionrecall.png){fig-align="center"}

Puedes profundizar un poco m√°s sobre este tema [en este art√≠culo](https://towardsdatascience.com/precision-and-recall-made-simple-afb5e098970f).

```{r}
perf <- h2o.performance(model = aml@leader, xval = TRUE)

metrics <- as.data.frame(h2o.metric(perf))

metrics |>
  ggplot(aes(recall, precision)) +
  geom_line() +
  theme_minimal()
```

```{r}
# Predicciones para test
predictions <- h2o.predict(object = aml@leader, newdata = titanic_test_h2o)
predictions
```

Para guardar el modelo generado en el directorio actual de tu computador y usarlo despu√©s, puedes usar este c√≥digo:

```{yaml}
h2o.saveModel(object = aml@leader, path = getwd(), force = TRUE)
```

```{r}
# Separamos dataset en test
titanic_test <- all_data |>
  filter(id == "test") |>
  select(-c(id, Survived, PassengerId, Name, Ticket, Cabin))

# Creamos el objeto H2O
titanic_test_h2o <- as.h2o(titanic_test)
```

```{r}
#| warning: false

# Predicciones en nuevo set de datos.
predictions_test <- h2o.predict(object = aml@leader, newdata = titanic_test_h2o)

# Separamos solo las predicciones.
survived <- as.data.frame(predictions_test$predict)
```

Ya que tenemos nuestas predicciones realizadas, generaremos el archivo para luego subir a Kaggle.

```{r}
#| warning: false

submission <- read_csv("gender_submission.csv") |>
  select(1)

gender_submission <- as.data.frame(cbind(submission, survived)) |>
  rename("Survived" = predict)

write.csv(gender_submission, "submission_autoML_leader_h2o.csv", row.names = FALSE)
```

```{r}
# Se apaga el cluster H2O
h2o.shutdown(prompt = FALSE)
```

## Subir a Kaggle

Subimos nuestro archivo a [Kaggle](https://www.kaggle.com/competitions/titanic/submit) y btenemos una puntuaci√≥n de 0.76076

No esta mal, pero podr√≠a ser mejor. Hace unos meses obtuve 0.79 usando un modelo de ML ensamblado GLM + GBM (Gradient Boosting Machine).

En este caso, para mejorar el desempe√±o del algoritmo que fue el seleccionado como l√≠der de la comparaci√≥n de autoML, habr√≠a que tocar los hiperpar√°metros y reanalizar el feature engineering. Adem√°s, de ver opciones de otros modelos de machine learning. Pero considerar que el modelo que usamos para este art√≠culo lo realizamos aplicando autoML. Es decir, usamos modelos pre-entrenados y con auto ajustes de hiperpar√°metros "out of the box" (predefinidos).

![](kaggle.png){fig-align="center" width="800"}

## Conclusiones

Este art√≠culo tiene fines demostrativos, no lo olvides. En la vida real, todo este proceso es (mucho) m√°s largo y complejo. Existen muchas instancias de an√°lisis estad√≠sticos y matem√©ticos sobre los datos dsponibles. Adem√°s, es un proceso iterativo. O sea, generalmente se vuelve a etapas previas frecuentemente, se revisa lo que hay. Incluso, muchas veces es necesario investigar sobre la generaci√≥n y captura de los datos. Del mismo modo, se generan muchos modelos y se realizan muchas pruebas hasta encontrar los de mejor desempe√±o y que tengan m√°s explicabilidad (seg√∫n sea el caso).

Revisamos, adem√°s, el uso de una tecnolog√≠a emergente que son los modelos de machine learning pre-entrenados o autoML. Este tipo de modelos est√°n cada vez m√°s difundidos, en especial, en ambientes cloud. Por ejemplo, [Google](https://cloud.google.com/automl/) y Microsoft Azure tienen los suyos.

El desarrollo de modelos de machine learning tradicional consume bastantes recursos, y que requieren un conocimiento del dominio y tiempo significativos para generar y comparar docenas de modelos. El autoML reduce el tiempo necesario para obtener modelos de aprendizaje autom√°tico listos para producci√≥n con gran eficiencia y facilidad. Estos elementos son vitales en la actualidad para muchas startups e industrias. Adem√°s, amplia las opciones en el uso de este tipo de tecnolog√≠as a m√°s personas y organizaciones.

A pesar de que parece magia todo √©sto (o una caja negra que nadie sabe lo que pasa dentro), el uso de autoML ayuda a generar modelos de forma m√°s r√°pida y facilita el desarrollo de modelos m√°s completos en el corto plazo. Es una buena estrategia para screening.

Ok. Entonces no necesitamos ingenieros, matem√°ticos o cient√≠ficos de datos?

No, para nada. Ciertamente estas tecnolog√≠as (autoML) democratizan el acceso a m√°s personas, pero a√∫n son necesarios los conocimientos y reflexiones de los expertos en el √°rea para ajustar los modelos, controlar sesgos o problemas de equidad. Y, por cierto, que conozcan del negocio, pues finalmente el desarrollo de estas tecnolog√≠as buscan resolver problem√°ticas concretas. Sin mencionar todo el trabajo de comunicaci√≥n, explicaci√≥n y disfusi√≥n de los resultados, para los cual esos perfiles profesionales son de gran valor.

Finalmente, este ejercicio que hemos visto ac√° es m√°s demostrativo que otra cosa, pero espero haberte mostrado c√≥mo se pueden entrenar algoritmos y usar modelos de ML para generar predicciones.

Nos vemos!! ü§™
