[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "r\n\n\ntutorial\n\n\nmachine learning\n\n\n\nEntreno 20 modelos de Machine Learning para averiguarlo.\n\n\n\nPaulo Villarroel\n\n\nOct 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr\n\n\ntutorial\n\n\n\nBreve tutorial sobre las funciones m√°s interesantes para trabajar con factores en R.\n\n\n\nPaulo Villarroel\n\n\nOct 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopensource\n\n\ntutorial\n\n\ngit\n\n\ngithub\n\n\n\nRevisemos c√≥mo contribuir a que crezca el conocimiento en el mundo!\n\n\n\nPaulo Villarroel\n\n\nOct 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npython\n\n\ncurso\n\n\n\nAprende desde cero el lenguaje de programaci√≥n m√°s usado y demandado del mundo.\n\n\n\nPaulo Villarroel\n\n\nOct 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquarto\n\n\ntutorial\n\n\n\nAhora que ya tenemos nuestro blog arriba, toca personalizarlo y dejarlo m√°s lindo.\n\n\n\nPaulo Villarroel\n\n\nSep 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquarto\n\n\ntutorial\n\n\n\nTe ense√±o a crear tu primer blog con Quarto, publicar nuevos art√≠culos, subirlo a GitHub y desplegarlo en la web.\n\n\n\nPaulo Villarroel\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre m√≠",
    "section": "",
    "text": "Emprendedor y fundador de la √∫nica comunidad de innovaci√≥n abierta en salud p√∫blica de Chile (OpenSalud LAB). Adem√°s, soy creador y coordinador del curso de Data Science en salud en espa√±ol m√°s grande del mundo."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/creando-mi-primer-blog/index.html",
    "href": "posts/creando-mi-primer-blog/index.html",
    "title": "Creando mi primer blog",
    "section": "",
    "text": "Este es el primer post de mi nuevo blog. Ac√° ir√© escribiendo sobre distintas tem√°ticas relacionadas al mundo de la programaci√≥n y la ciencia de datos.\nBienvenido/a nuevamente.\nEn esta oportunidad te voy a ense√±ar a crear tu propio blog, como el que est√°s viendo ahora. Si! Como este mismo. Te parece?\nPues vamos a ello!!\nLo primero que debes saber es que este blog est√° constru√≠do sobre la base Quarto. Quarto es una nueva plataforma open-source, lanzada hace poco tiempo, y que busca facilitar la publicaci√≥n de art√≠culos cient√≠ficos. La gracia que tiene es que soporta distintos lenguajes de programaci√≥n (R, Python, Julia) en una sola aplicaci√≥n.\nBueno, dentro de las cosas que permite hacer Quarto es crear un blog. Que es lo que haremos ahora.\n\n\nLo primero que tienes que hacer es descargar Quarto desde su web oficial. Elige la versi√≥n que corresponda a tu sistema operativo. La instalaci√≥n no tiene ninguna cosa extra√±a, es como cualquier programa nada m√°s.\n\n\n\n\n\nEn lo personal, estoy usando RStudio como editor de texto, pero se pueden usar otros como Visual Studio Code o Jupyter Notebooks. En este caso, explicar√© los pasos para RStudio.\n\n\n\nSi est√°s familiarizado con RStudio, sabr√°s lo que es un proyecto. Si no, pues un proyecto es un conjunto de archivos que se mantienen relacionados entre s√≠, de modo que sea m√°s simple el desarrollo y vinculaci√≥n. Adem√°s, de facilitar el uso de rutas relativas lo cual es genial a la hora de compartir c√≥digo o de proyectos m√°s grandes.\nEn RStudio debes ir al men√∫ superior y seleccionar New Project‚Ä¶\n\n\n\n\n\nEso te abrir√° una nueva pesta√±a, en donde debes seleccionar la opci√≥n New Directory.\n\n\n\n\n\nLuego, debes eligir el tipo de proyecto. En este caso, selecciona Quarto Blog.\n\n\n\n\n\nSe abrir√° una nueva ventana. Ac√° debes poner el nombre de la carpera que vas a crear (en Directory name). Verifica la carpeta en donde vas a crear este directorio. Luego dale a Create Project.\n\n\n\n\n\nCon eso, Quarto te crear√° una serie de archivos y la estructura del blog de forma autom√°tica!!!\nVer√°s que ahora tienes muchos archivos nuevos en tu visor.\n\n\n\n\n\n\n\n\nCon los pasos anteriores, Quarto te cre√≥ un blog completamente funcional. Eso si, con art√≠culos de muestra que despu√©s hay que eliminar o modificar, obviamente. Pero ya tienes la base.\nPara revisar c√≥mo se ve tu blog, debes darle clic al bot√≥n Render de la parte superior.\n\n\n\n\n\nVer√°s una serie de cosas que van a sair en la consola de RStudio, pero es parte del proceso de renderizado. O sea, para armar el blog y pasar los archivos a una p√°gina web.\nSi todo sale bien, se deber√≠a abrir tu blog en una pesta√±a de tu navegador."
  },
  {
    "objectID": "posts/creando-mi-primer-blog-con-quarto/index.html",
    "href": "posts/creando-mi-primer-blog-con-quarto/index.html",
    "title": "Creando mi primer blog con Quarto",
    "section": "",
    "text": "Hola!! ü§ò\nEste es el primer post de mi nuevo blog. Ac√° ir√© escribiendo sobre distintas tem√°ticas relacionadas al mundo de la programaci√≥n y la ciencia de datos.\nBienvenido/a nuevamente.\nEn esta oportunidad te voy a ense√±ar a crear tu propio blog, como el que est√°s viendo ahora. Si! Como este mismo. Te parece?\nPues vamos a ello!!\nLo primero que debes saber es que este blog est√° constru√≠do sobre la base Quarto. Quarto es una nueva plataforma open-source, lanzada hace poco tiempo, y que busca facilitar la publicaci√≥n de art√≠culos cient√≠ficos. La gracia que tiene es que soporta distintos lenguajes de programaci√≥n (R, Python, Julia) en una sola aplicaci√≥n.\nBueno, dentro de las cosas que permite hacer Quarto es crear un blog. Que es lo que haremos ahora."
  },
  {
    "objectID": "posts/personalizado-el-blog/index.html",
    "href": "posts/personalizado-el-blog/index.html",
    "title": "Personalizando el blog",
    "section": "",
    "text": "Ya tenemos nuestro blog!\nY ya que al subir este nuevo post, voy a cambiar la configuraci√≥n, te dejo esta imagen de la versi√≥n original del cual parto.\nAhora toca cambia algunas cosas para que el blog sea m√°s funcional y adecuado."
  },
  {
    "objectID": "posts/personalizado-el-blog/index.html#cambiando-el-t√≠tulo",
    "href": "posts/personalizado-el-blog/index.html#cambiando-el-t√≠tulo",
    "title": "Personalizando el blog",
    "section": "Cambiando el t√≠tulo",
    "text": "Cambiando el t√≠tulo\nEntre esas cosas, quiero cambiar el t√≠tulo del blog. Ahora dice ‚Äúmi_blog‚Äù, que es el nombre del archivo en donde tengo el proyecto completo y que al crear el blog con Quarto, toma este nombre (del archico) por defecto. Pero es feo y quiero cambiarlo por algo m√°s representativo.\nDentro de las carpetas y estructura que se crean por defecto, en la raiz del proyecto hay un archivo que se llama _quarto.yml. Este es un archivo YAML que contiene algunos datos de configuraci√≥n general del blog.\n\n\n\n\n\nSi te fijas, ah√≠ est√° el t√≠tulo del blog, el ‚Äúmi blog‚Äù que deseo cambiar.\nPues bueno, entonces habr√° que modificarlo. Voy a poner mi direcci√≥n web paulovillarroel.com que es un dominio que compr√© hace unos d√≠as y lo configur√© en mi cuenta de Netlify para linkearla a mi blog. Hacer eso es bastante simple. La web de Netlify es bien intuitiva.\nPues bueno‚Ä¶\nPara ver los cambios que voy realizando en el blog, sin necesidad de renderizar y desplegar nada (no es buena idea hacer todo es cada vez que se hacen cambios, pues la idea es hacerlo cuando cuando ya se tienen varios cambios finalizados y que comprobamos que funcionan y nos gustan). Para ello, lo que har√© es previsualizar la web.\nEso se hace del men√∫ superior de RStudio, en la pesta√±a de Build est√° la opci√≥n de Preview Website. Esto abrir√° una pesta√±a del navegador con el preview de lo que estamos haciendo.\n\n\n\n\n\nOk!! Vamos avanzando!! üéâ\nYa tenemos cambiado el nombre de la web, arriba a la izquierda. Y aparace una nueva entrada a blog que es este mismo art√≠culo que estoy escribiendo.\nPero sigue apareciendo ‚Äúmi_blog‚Äù como una especia de t√≠tulo.\nPara modificar esa secci√≥n, es necesario cambiar algunas cosas de la p√°gina que estamos visualizando. En la carpeta ra√≠z del proyecto, tenemos el archivo index.qmd. Si lo abrimos, nos encontramos con lo siguiente:\n\n\n\n\n\nVemos que tiene como t√≠tulo ‚Äúmi_blog‚Äù. Maravilloso!!!\nAhora procedemos a cambiarlo. En mi caso le he puesto simplemente Blog.\nHay varias opciones de configuraci√≥n aqu√≠, pero por ahora las dejaremos igual. Ya las retomar√© m√°s adelante.\nF√≠jate que si ya tienes la pesta√±a del navegador abierta (la que se abri√≥ al hacer clic en Preview) y la actualizas, se ver√°n reflejados los cambios (debes guardarlos antes eso si). Recuerda que este preview est√° solo en tu computador y no en la versi√≥n publicada en la web. Por eso la direcci√≥n sale localhost, que es tu pc."
  },
  {
    "objectID": "posts/personalizado-el-blog/index.html#cambiando-links",
    "href": "posts/personalizado-el-blog/index.html#cambiando-links",
    "title": "Personalizando el blog",
    "section": "Cambiando links",
    "text": "Cambiando links\nSi eres curioso/a, te habr√°s dado cuenta que los links de los √≠conos que salen arriba a la derecha te llevan a las web oficiales de GitHub y Twitter. Bueno, eso es algo que debemos cambiar, para poner los link a mis redes sociales respectivas.\nEn el archivo _quarto.yml que ya vimos antes, est√°n los link para modificarlos. Pongo mis links correctos y aprovecho de agregar mi perfil de LinkedIn.\nFinalmente, me queda as√≠‚Ä¶"
  },
  {
    "objectID": "posts/personalizado-el-blog/index.html#cambiando-el-tema",
    "href": "posts/personalizado-el-blog/index.html#cambiando-el-tema",
    "title": "Personalizando el blog",
    "section": "Cambiando el tema",
    "text": "Cambiando el tema\nEl tema por defecto del blog no est√° mal, pero me gustar√≠a probar otro.\nQuarto usa Bootstrap 5 y Boostwatch para los temas. Tiene 25 temas ya inlcu√≠dos por defecto, los cuales los puedes ver y revisar en la web de Quarto.\nEn mi caso usar√© el tema darkly, ya que me gustan los temas oscuros.\nPara cambiar el tema tan solo debes cambiar el nombre que aparece en theme en el YAML. Sin embargo, podemos hacer algo interesante ac√° y es agregar la opci√≥n de tener 2 temas, uno claro y otro oscuro para que sea el usuario quien pueda elegir cual le acomode m√°s. Para eso, en la secci√≥n themes debemos hacer lo siguiente:\n\n\n\n\n\nLa verdad, es que podr√≠amos cambiar muchas m√°s cosas del tema, incluso crear un tema propio. Para ello, tendr√≠amos que tocar el CSS, pero este es un tutorial para principiantes, as√≠ que no me voy a meter en esos temas por ahora. Pero cre√©me, conocer de HTML y CSS es algo muy √∫til. Te lo dejo ah√≠.\nNota que puse la versi√≥n dark arriba de la light, pues quiero que esa sea la por defecto al entrar a la web."
  },
  {
    "objectID": "posts/personalizado-el-blog/index.html#cambiando-el-layout",
    "href": "posts/personalizado-el-blog/index.html#cambiando-el-layout",
    "title": "Personalizando el blog",
    "section": "Cambiando el layout",
    "text": "Cambiando el layout\nHasta ahora, el blog se ve de esta forma:\n\n\n\n\n\nPero esa configuraci√≥n de c√≥mo se ven los art√≠culo no me termina de convencer.\nSi revisamos la web de Quarto, tenemos varias opciones para el layout:\n\ndefault\ngrid\ntable\n\nPara modificar esta configuraci√≥n, debemos hacerlo del archivo index.qmd de la raiz del proyecto. En la secci√≥n listing/type.\nDe las 3 opciones, me gusta m√°s la opci√≥n de grid. Con ello, el blog queda algo as√≠‚Ä¶"
  },
  {
    "objectID": "posts/personalizado-el-blog/index.html#agregando-comentarios",
    "href": "posts/personalizado-el-blog/index.html#agregando-comentarios",
    "title": "Personalizando el blog",
    "section": "Agregando comentarios",
    "text": "Agregando comentarios\nUna de las cosas interesantes de un blog es la interacci√≥n con los visitantes. Y una de las opciones interesantes que te ofrece Quarto es agregar la posibilidad de que las personas puedan escribir comentarios en los art√≠culos.\nEn la web de Quarto puedes leer m√°s detalles de esta implementaci√≥n.\nEn este caso, yo usar√© Giscus, que se basa en los comentarios de GitHub. Aprovecharemos la instancia que ya tenemos nustro blog en Github para usar esta funcionalidad.\nOk, vamos con esto‚Ä¶\n\nTenemos que ir a la web de Giscus y darle al bot√≥n install.\n\n\n\n\n\n\n\nDebemos elegir el repositorio de GitHub al cual haremos referencia, en este caso, el que creamos en el art√≠culo anterior.\n\n\n\n\n\n\n\nLe damos a Install.\nEs posible que GitHub te pida algunos permisos o verificaciones.\nDebes asegurarte que tienes las discusiones habilitadas en tu repositorio. Si no has cambiado nada, por defecto la debes tener desactivadas. Para activarlas, tienes que ir a tu repositorio del blog e ir a Settings.\n\n\n\n\n\n\n\nEn la secci√≥n de configuraci√≥n (settings) baja un poco en la p√°gina. Encontrar√°s una secci√≥n llamada Features. Marca la opci√≥n de Discussions.\n\n\n\n\n\n\n\nAnda al archivo _quarto.yml y agrega este c√≥digo:\n\n\ncomments:\n  giscus:\n    repo: YOURGITHUBACCOUNT/YOURREPO\nL√≥gicamente, en donde dice repo debes poner la direcci√≥n web de tu repositorio de GitHub en donde tienes el proyecto.\nEn mi caso, queda as√≠:\n\n\n\n\n\n\nPor defecto, al agregar esta ll√≠nea de c√≥digo se pondr√° en cada p√°gina de la web la opci√≥n de discusiones. En mi caso, solo quiero √©sto para los art√≠culos, pero no para la parte en donde muestro todos los art√≠culos y otras partes como el about (que no lo hemos tocado hasta ahora, por cierto).\nPara evitar √©sto, debemos incluir en el YAML de los .qmd respectivos el siguiente c√≥digo:\n\n\ncomments: false"
  },
  {
    "objectID": "posts/personalizado-el-blog/index.html#algunos-toques-finales",
    "href": "posts/personalizado-el-blog/index.html#algunos-toques-finales",
    "title": "Personalizando el blog",
    "section": "Algunos toques finales",
    "text": "Algunos toques finales\nPara darle algunos toques finales a la personalizaci√≥n del blog, te dejo como dej√© mi archivo _quarto.yml\nproject:\n  type: website\n\nwebsite:\n  title: \"PauloVillarroel.com\"\n  site-url: \"https://www.paulovillarroel.com/\"\n  google-analytics: \"G-RNWVZS7ZL8\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/paulovillarroel\n      - icon: twitter\n        href: https://twitter.com/Chazkon\n      - icon: linkedin\n        href: https://www.linkedin.com/in/paulovillarroeltapia/\nformat:\n  html:\n    smooth-scroll: true\n    theme:\n      dark: darkly\n      light: flatly\n    css: styles.css\n    link-external-newwindow: true\n\neditor: visual\n\ncomments:\n  giscus:\n    repo: paulovillarroel/mi_blog\nOk\nYa estamos terminando este art√≠culo. Espero que te haya sido √∫til.\nA√∫n faltan cosas por configurar y personalizar, pero hemos avanzado bastante por ahora.\nNos vemos!! üöÄ"
  },
  {
    "objectID": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-1-descargar-quarto",
    "href": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-1-descargar-quarto",
    "title": "Creando mi primer blog con Quarto",
    "section": "Paso 1: Descargar Quarto",
    "text": "Paso 1: Descargar Quarto\nLo primero que tienes que hacer es descargar Quarto desde su web oficial. Elige la versi√≥n que corresponda a tu sistema operativo. La instalaci√≥n no tiene ninguna cosa extra√±a, es como cualquier programa nada m√°s.\n\n\n\n\n\nEn lo personal, estoy usando RStudio como editor de texto, pero se pueden usar otros como Visual Studio Code o Jupyter Notebooks. En este caso, explicar√© los pasos para RStudio."
  },
  {
    "objectID": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-2-crea-un-proyecto",
    "href": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-2-crea-un-proyecto",
    "title": "Creando mi primer blog con Quarto",
    "section": "Paso 2: Crea un proyecto",
    "text": "Paso 2: Crea un proyecto\nSi est√°s familiarizado con RStudio, sabr√°s lo que es un proyecto. Si no, pues un proyecto es un conjunto de archivos que se mantienen relacionados entre s√≠, de modo que sea m√°s simple el desarrollo y vinculaci√≥n. Adem√°s, de facilitar el uso de rutas relativas lo cual es genial a la hora de compartir c√≥digo o de proyectos m√°s grandes.\nEn RStudio debes ir al men√∫ superior y seleccionar New Project‚Ä¶\n\n\n\n\n\nEso te abrir√° una nueva pesta√±a, en donde debes seleccionar la opci√≥n New Directory.\n\n\n\n\n\nLuego, debes eligir el tipo de proyecto. En este caso, selecciona Quarto Blog.\n\n\n\n\n\nSe abrir√° una nueva ventana. Ac√° debes poner el nombre de la carpera que vas a crear (en Directory name). Verifica la carpeta en donde vas a crear este directorio. Luego dale a Create Project.\n\n\n\n\n\nCon eso, Quarto te crear√° una serie de archivos y la estructura del blog de forma autom√°tica!!!\nVer√°s que ahora tienes muchos archivos nuevos en tu visor."
  },
  {
    "objectID": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-3-preview-de-tu-blog",
    "href": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-3-preview-de-tu-blog",
    "title": "Creando mi primer blog con Quarto",
    "section": "Paso 3: Preview de tu blog",
    "text": "Paso 3: Preview de tu blog\nCon los pasos anteriores, Quarto te cre√≥ un blog completamente funcional. Eso si, con art√≠culos de muestra que despu√©s hay que eliminar o modificar, obviamente. Pero ya tienes la base.\nPara revisar c√≥mo se ve tu blog, debes darle clic al bot√≥n Render de la parte superior.\n\n\n\n\n\nVer√°s una serie de cosas que van a sair en la consola de RStudio, pero es parte del proceso de renderizado. O sea, para armar el blog y pasar los archivos a una p√°gina web.\nSi todo sale bien, se deber√≠a abrir tu blog en una pesta√±a de tu navegador.\nY listo!!!\nYa tienes tu primer blog üéâ\nEs posible que tu blog se muestra en el mismo RStudio en una ventana lateral. Esa opci√≥n me parece que viene por defecto (no recuerdo bien), pero yo la tengo configurada para que me aparezca el preview en una ventana del navegador. Me gusta m√°s esa opci√≥n, pues se ve mejor el contenido. Para poner esa opci√≥n, debes darle clic a la tuerca que est√° al lado derecho del bot√≥n Render y seleccionar Preview in Window.\n\nF√≠jate que la web est√° en tu computador y se est√° mosrando desde una direcci√≥n que dice localhost. Esto es por ese mismo motivo. A pesar de que se ve como una web a trav√©s de tu navegador, el blog solo est√° en tu computador. No est√° subido a internet ni alojado en ning√∫n servicio que permita que otros lo vean. Para eso, hay que hacer algunas cosas, que las veremos un poco m√°s adelante."
  },
  {
    "objectID": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-4-crear-un-post",
    "href": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-4-crear-un-post",
    "title": "Creando mi primer blog con Quarto",
    "section": "Paso 4: Crear un post",
    "text": "Paso 4: Crear un post\nCuando creas tu proyecto de blog con Quarto, la aplicaci√≥n crea la estructura y pone 2 post de ejemplo.\nSi observas los archivos, ver√°s una carpeta llamada posts. En esta carpeta es donde se deben ir guardando los archivos para los nuevos posts.\nPor defecto te crea 2 carpetas: welcome y post-with-code\nEsos son post de muestra, que los puedes eliminar. Pero antes que lo hagas, quiero que te fijes en c√≥mo estan estructurados. Esa ser√° la forma en que deber√°s crear tu pr√≥ximas entradas.\nCada art√≠culo (o post) consiste en una carpeta. Dentro de ella hay un archivo index.qmd y algunas im√°genes.\nEsta es la estructura de archivos que se te crear√° de forma autom√°tica:\n\nCreated _quarto.yml\nCreated index.qmd}\nCreated posts/welcome/index.qmd\nCreated posts/post-with-code/index.qmd\nCreated about.qmd\nCreated styles.css\nCreated posts/_metadata.yml\n\nEn la carpeta posts crea un nuevo archivo con el nombre de tu nueva entrada. Dentro de esa carpeta, crea un archivo .qmd y ll√°malo index. Es decir, te deber√≠a quedar un archivo de nombre index.qmd\nEsto es fundamental. Siempre usa index para nombrar a los nuevos posts. De lo contrario, Quarto no encontrar√° el archivo al cual hacer referencia para renderizar adecuadamente la web.\nSi ya est√°s familiarizado/a con R Markdown, notar√°s que trabajar con Quarto es muy similar. De hecho, los archivos .qmd tienen la misma estructura. Un encabezado (YAML) con algunas cinfiguraciones generales y luego el espacio para escribir texto.\nPara este post, us√© este YAML:\n\n\n\n\n\nEn art√≠culos posteriores veremos c√≥mo configurar el YAML, pues tiene muchas opciones.\nAhora que ya tienes creada una nueva carpeta dentro de posts y agregaste el index.qmd, b√°sicamente ya tienes un nuevo art√≠culo listo para el blog.\nGuarda todos los cambios y dale a Render nuevamente. Si ya ten√≠as abierto el blog en tu navegador, deber√≠an verse reflejados los cambios realizados. Si no pasa eso, actualiza la p√°gina para ver los cambios.\nAs√≠ se ve mi blog, solo con 1 art√≠culo publicado (que es este)."
  },
  {
    "objectID": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-5-subiendo-el-blog-a-github",
    "href": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-5-subiendo-el-blog-a-github",
    "title": "Creando mi primer blog con Quarto",
    "section": "Paso 5: Subiendo el blog a GitHub",
    "text": "Paso 5: Subiendo el blog a GitHub\nMe encanta el open-source y el compartir c√≥digo. Y una de las mejores formas de dejarlo publicado en GitHub.\nPara hacerlo, desde RStudio es bastante simple. Ah! Debes tener una cuenta ya creada en GitHub y tener GIT instalado.\nTeniendo lo anterior ya realizado, podemos usar la librer√≠a {usethis} para simplificar el proceso. Ac√° puedes ver la documentaci√≥n oficial.\nPrimero, instalamos la librer√≠a:\ninstall.packages(\"usethis\")\nConfiguramos nuestras credenciales (los datos que usamos para la cuenta de GitHub):\nusethis::use_git_config(\n   # your name\n   user.name = \"Mi nombre\",\n   # your email used in your GitHub account\n   user.email = \"micorreo@gmail.com\"\n )\nCreamos nuestro GitHub PAT Token con usethis::create_github_token() (es como una contrase√±a, pero m√°s segura). Cuando ejecutas este comando, se te abrir√° una pesta√±a de tu navegador. Tendr√°s que verificar algunos permisos a GitHub. Luego, en la configuraci√≥n del token, cambia el nombre, ajustael tiempo de expiraci√≥n y el resto d√©jalo como est√°. Crea el token.\nSe te mostrar√° una nueva p√°gina con tu claves.\nPara guardar tu nuevo token, usa gitcreds::gitcreds_set(). En la consola se te mostrar√° un men√∫. Selecciona la opci√≥n 2 Replace these credentials. Luego copia el token de GitHub, actualiza y guarda tus credenciales.\nReinicia la sesi√≥n de RStudio para que se hagan efectivos los cambios. Usualmente puedes usar CTRL + SHIFT + F10 o del men√∫ de arriba selecciona la pesta√±a de Session y luego Restart R.\nUsa usethis::git_sitrep() para verificar si tus credenciales como nombre, email y PAT est√°n correctamente configuradas.\nF√≠jate que salga este texto Personal access token for 'https://github.com': '<discovered>'\nCon eso ya deber√≠amos estar listos con la configuraci√≥n de GIT y GitHub.\nAhora configuremos algunas cosas m√°s‚Ä¶\nUsaremos use_git() para iniciar el control de versiones de GIT en nuestro proyecto.\nusethis::use_git()\n‚úî Setting active project to '/Users/Desktop/name-of-your-blog/'\n‚úî Initialising Git repo\n‚úî Adding '.Rproj.user', '.Rhistory', '.Rdata', '.httr-oauth', '.DS_Store' to '.gitignore'\nThere are 8 uncommitted files:\n* '_quarto.yml'\n* '.gitignore'\n* 'about.qmd'\n* 'example-quarto-blog.Rproj'\n* 'index.qmd'\n* 'posts/'\n* 'profile.jpg'\n* 'styles.css'\n\n\nIs it ok to commit them?\n\n1: Not now\n2: Yup\n3: Negative\n\nSelection: 2\n\n\n‚úî Adding files\n‚úî Making a commit with message 'Initial commit'\n‚Ä¢ A restart of RStudio is required to activate the Git pane\nRestart now?\n\n1: No way\n2: Definitely\n3: No\n\nSelection: 2\nAhora, usaremos use_github() para crear un repositorio en GitHub y subir el proyecto.\nusethis::use_github()\nSi todo ha salido bien, se deber√≠a abrir tu navegador con el nuevo repositorio de GitHub.\nAc√° puedes ver el repositorio de este proyecto."
  },
  {
    "objectID": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-6-desplegar-con-netlify",
    "href": "posts/creando-mi-primer-blog-con-quarto/index.html#paso-6-desplegar-con-netlify",
    "title": "Creando mi primer blog con Quarto",
    "section": "Paso 6: Desplegar con Netlify",
    "text": "Paso 6: Desplegar con Netlify\nAhora vamos a publicar nuestro blog en internet para que otros lo puedan ver. Recuerda que hasta ahora, sigue estando solo en tu computador.\nPara hacer el deploy (despliegue) usaremos Netlify.\nEste es un servicio que har√° que el blog est√© disponible en una direcci√≥n web. Adem√°s, entre otras funciones super interesantes, tiene la opci√≥n de conectarlo a un repositorio de GitHub, que es lo que haremos en este caso.\nUsaremos esta opci√≥n, ya que nos ayudar√° a ser m√°s transparentes en todo el flujo de trabajo y podremos desplegar los cambios que vayamos realizando en nuestro proyecto y repo de GitHub.\nPara eso, primero deber crearte una cuenta en Netlify. Mi recomendaci√≥n es que lo hagas usando tu cuenta de GitHub.\nUna vez iniciada sesi√≥n, se te mostrar√° algo as√≠:\n\n\n\n\n\nEn la secci√≥n Sites, dale clic a Import from Git.\nSelecciona GitHub.\n\n\n\n\n\nSe comenzar√° a sincronzar con tu perfil de GitHub y te mostrar√° todos los respositorio disponibles.\nElige el que acabamos de crear, donde est√° nuestro blog.\nSe mostrar√° algunos detalles. Ac√° debes ingresar en Base directory _site, como se muestra en la imagen.\nEste paso es importante, de lo contrario no funcionar√° tu web.\n\n\n\n\n\nDale al bot√≥n Deploy site.\nTe va a salir algo como esto‚Ä¶\n\n\n\n\n\nSi no cambia el estado y sigue saliendo el mensaje Site deply in progress, puedes actualizar la p√°gina de tu navegador. Habitualmente este proceso es r√°pido y solo toma unos segundos.\n\n\n\n\n\nSi todo anda bien, deber√≠a estar ya desplegado nuestro blog.\nPara acceder a √©l, anda al link que te ponen (xxxx.netlify.app).\nEsta es una direcci√≥n web con un nombre aleatorio que te da Netlify. La podemos cambiar en la configuraci√≥n por algo que nos haga m√°s sentido. E incluso, podemos usar nustro propio dominio si es que lo tenemos.\nSe abrir√° una pesta√±a en tu navegador, mostrando tu blog!!! üòç\n\n\n\n\n\nEn Netlify, en la secci√≥n de Site settings podemos encontrar la opci√≥n para cambiar la direcci√≥n web.\nPara ello, debemos dar clic en Change site name.\n\n\n\n\n\nSe te abrir√° una ventana. Ingresa el nombre que desees y listo.\nCambiado el nombre. Nota que este cambio de nombre cambia la direcci√≥n web, por lo que si has compartido el link previo, este ya no funcionar√°. Ten cuidado con cambiar el nombre a cada rato.\nEspero que este tutorial te haya servido y que puedas tener tu propio blog.\nEn pr√≥ximas entradas, estar√© revisando c√≥mo hacer ajustes al blog, personalizar algunas cosas est√©ticas y agregarle algunas funcionaidades.\nNos vemos! üòú\n\n\nüëâ Revisa la segunda parte de este tutorial en este enlace."
  },
  {
    "objectID": "posts/contribuye-al-codigo-abierto/index.html",
    "href": "posts/contribuye-al-codigo-abierto/index.html",
    "title": "Contribuye al c√≥digo abierto",
    "section": "",
    "text": "Hola (otra vez!!)\nHoy te quiero hablar de un tema, que considero, muy relevante: el c√≥digo abierto.\nEn ingl√©s al c√≥digo abierto se le denomina open source. Y es que m√°s que una forma de desarrollar c√≥digo de forma colaborativa, es una filosof√≠a o un movimiento. Es una l√≥gica que supera solo a la producci√≥n del software mismo, sino que abarca valores del dise√±o descentralizado y soluci√≥n de problemas de forma colectiva y abierta. Si deseas saber un poco m√°s del open source, puedes revisar este link.\nEn lo personal, me encanta esta filosof√≠a del open source. Y es que esta forma de trabajo puede abarcar no solo el desarrollo de c√≥digo, sino que de otras industrias y √°reas. La innovaci√≥n tiene mucho de √©sto, de desarrollar soluciones de forma colaborativa y abierta.\nHoy quiero que tu puedas contribuir al c√≥digo abierto. Si!! Que ayudes a generar conocimiento colectivo. Entonces debes conocer un par de cosas. Una de √©stas es el control de versiones GIT y la otra es alguna plataforma de repositorios remotos , como GitHub, GitLab o Bitbucket.\nPero cuando me puse a pensar en c√≥mo explicarte a contribuir al c√≥digo abierto, me parece relevante explicarte un paso antes. Y es que para que puedas hacer estas cosas, debes conocer algo de GIT."
  },
  {
    "objectID": "posts/contribuye-al-codigo-abierto/index.html#qu√©-es-git",
    "href": "posts/contribuye-al-codigo-abierto/index.html#qu√©-es-git",
    "title": "Contribuye al c√≥digo abierto",
    "section": "¬øQu√© es GIT?",
    "text": "¬øQu√© es GIT?\nEn la web de Microsoft indican:\nGit es un sistema de control de versiones distribuido, lo que significa que un clon local del proyecto es un repositorio de control de versiones completo. Estos repositorios locales plenamente funcionales permiten trabajar sin conexi√≥n o de forma remota con facilidad. Los desarrolladores confirman su trabajo localmente y, a continuaci√≥n, sincronizan su copia del repositorio con la copia en el servidor. Este paradigma es distinto del control de versiones centralizado, donde los clientes deben sincronizar el c√≥digo con un servidor antes de crear nuevas versiones.\nYa te contar√© m√°s sobre GIT en otros art√≠culos. En esta oportunidad ser√© muy concreto. Te explicar√© c√≥mo instalar GIT en tu computador para que puedas empezar a contribuir a proyectos de c√≥digo abierto lo antes posible."
  },
  {
    "objectID": "posts/contribuye-al-codigo-abierto/index.html#pasos-para-instalar-git",
    "href": "posts/contribuye-al-codigo-abierto/index.html#pasos-para-instalar-git",
    "title": "Contribuye al c√≥digo abierto",
    "section": "Pasos para instalar GIT",
    "text": "Pasos para instalar GIT\nInstalar GIT no es nada complejo. Es como cualquier programa que instalas. B√°sicamente es descargar el instalador y darle clic a ‚Äúsiguiente‚Äù muchas veces.\nDe todas formas, hace unos meses me toc√≥ instalar GIT y tom√© capturas de pantalla de cada paso. Te las dejo para que te sirvan de referencia.\n\n\n\nVersi√≥n de GIT Puede que la versi√≥n que instales no sea la misma que muestro ac√°, pero la instalaci√≥n no deber√≠a ser muy distinta."
  },
  {
    "objectID": "posts/contribuye-al-codigo-abierto/index.html#finalmente",
    "href": "posts/contribuye-al-codigo-abierto/index.html#finalmente",
    "title": "Contribuye al c√≥digo abierto",
    "section": "Finalmente‚Ä¶",
    "text": "Finalmente‚Ä¶\nSi sigues los pasos, no deber√≠as tener mayor dificultades para tener instalado GIT.\nEso es lo primero para empezar a contribuir al open source.\nEn el pr√≥ximo art√≠culo te explicar√© de forma muy precisa, c√≥mo hacer tu primera pull request, que es la forma por excelencia de contribuir a proyectos abiertos. Pero eso, lo veremos en detalle en mi pr√≥ximo art√≠culo.\nNos vemos!!! üòÅ"
  },
  {
    "objectID": "posts/ruta-aprendizaje-python/index.html",
    "href": "posts/ruta-aprendizaje-python/index.html",
    "title": "Mi ruta de aprendizaje en Python",
    "section": "",
    "text": "Hola!\nTe quiero contar que, desde hace varias semanas, que estoy estudiando Python. Este ser√≠a mi tercer lenguaje de programaci√≥n, luego de R y SQL.\nYo me dedico, principalmente, al an√°lisis de datos y aplicaciones de inteligencia artificial, por lo cual este stack de tecnolog√≠a me parece bastante potente.\nA continuaci√≥n te explico porqu√© decid√≠ aprender Python y hacerlo de esta forma."
  },
  {
    "objectID": "posts/ruta-aprendizaje-python/index.html#por-qu√©-aprender-python",
    "href": "posts/ruta-aprendizaje-python/index.html#por-qu√©-aprender-python",
    "title": "Mi ruta de aprendizaje en Python",
    "section": "¬øPor qu√© aprender Python?",
    "text": "¬øPor qu√© aprender Python?\nPython es el lenguaje de programaci√≥n ‚Äúm√°s famoso‚Äù en la actualidad a nivel mundial. Bueno, si no es el primero, est√° entre los 3 primeros seguro, va a depender de la encuesta que se mire (tiene una lucha a muerte con JavaScript jajaj). Pero es innegable que este lenguaje es ampliamente buscado y las ofertas laborales son cada vez m√°s necesitadas, en especial, en temas de an√°lisis de datos, inteligencia artificial, IoT y backend.\nSi miramos Google Trends, podemos ver que el inter√©s por este lenguaje de programaci√≥n ha ido creciendo, en especial, desde el 2015 en adelante.\n\n\nPosiblemente eso tenga relaci√≥n con el auge de la inteligencia artificial, en donde Python es uno de los lenguajes m√°s usados.\nPor otra parte, si revisamos el TIOBE Index para el mes de septiembre 2022, vemos que Python se posiciona en el primer puesto del ranking, con tendencia al alza respecto del mes pasado.\n\n\n\n\n\nEn la encuesta 2022 de desarrolladores que hace StackOverflow, nuevamente vemos a Python entre los primeros lugares de los lenguajes m√°s usados.\n\n\n\n\n\nA ver, que un lenguaje sea el m√°s buscado, m√°s famoso y esas cosas no es tan importante. La verdad que lo que deber√≠a ser determinante es la utilidad que te ofrece aprenderlo. En mi caso, me sirve üòé, pues para temas de an√°lisis de datos es uno de los m√°s relevantes en la actualidad."
  },
  {
    "objectID": "posts/ruta-aprendizaje-python/index.html#por-qu√©-hacer-una-web",
    "href": "posts/ruta-aprendizaje-python/index.html#por-qu√©-hacer-una-web",
    "title": "Mi ruta de aprendizaje en Python",
    "section": "¬øPor qu√© hacer una web?",
    "text": "¬øPor qu√© hacer una web?\nEn aprendiendopython.com estoy documentando gran parte de lo que voy estudiando sobre Python.\nDecid√≠ hacer eso por varios motivos‚Ä¶\n\nMe gusta ense√±ar y me parece que puedo contribuir en ese sentido.\nLa mejor forma de estudiar y aprender algo, es ense√±√°ndolo. Al explic√°rselo a otras personas, el aprendizaje es mucho m√°s significativo y la curva es mucho m√°s r√°pida. Esta es una metodolog√≠a que uso bastante.\nA pesar de que estoy reci√©n aprendiendo Python, ya tengo conocimientos en programaci√≥n (soy programador desde hace un par de a√±os), lo cual hace que aprender un nuevo lenguaje sea mucho m√°s simple. Sin embargo, en este proyecto decid√≠ obviar un poco mis conocimientos previos e intentar explicar todo desde los m√°s simple y b√°sico, de modo que cualquiera pueda entenderlo. O, al menos, esa es mi intenci√≥n.\nIr documentando mi aprendizaje me ayuda a ir dejando un manual de estudio y notas para el futuro. En general, uno se puede aprender gran parte de las cosas de memoria y entender la l√≥gica, pero la sintaxis puede que se olvide. El contar con este material de apoyo me permitir√° tener acceso simple a esas cosas si es que lo llegara a necesitar."
  },
  {
    "objectID": "posts/ruta-aprendizaje-python/index.html#basado-en-proyectos",
    "href": "posts/ruta-aprendizaje-python/index.html#basado-en-proyectos",
    "title": "Mi ruta de aprendizaje en Python",
    "section": "Basado en proyectos",
    "text": "Basado en proyectos\nAdem√°s de ense√±ar lo que se va aprendiendo, otra forma de ir consolidando de mejor forma los conocimientos, es el realizar proyectos.\nLlevar a la pr√°ctica distintas cosas, en proyectos peque√±os, pero que permitan entender el funcionamiento del lenguaje.\nYa hice uno y lo tengo publicado. Es un peque√±o script para identificar el signo del zodiaco chino que te corresponde, seg√∫n el a√±o de nacimiento.\nyear = int(input(\"Ingresa el a√±o de nacimiento: \"))\n\ndef chinese_zodiac(year:int):\n    elements = (\"madera\", \"fuego\", \"tierra\", \"metal\", \"agua\")\n    animals = (\"rata\", \"buey\", \"tigre\", \"conejo\", \"drag√≥n\", \"serpiente\", \"caballo\", \"oveja\", \"mono\", \"gallo\", \"perro\", \"cerdo\")\n\n    if year < 604:\n        print(\"El ciclo sexagenario chino comenz√≥ en el a√±o 604. Debes introducir un a√±o adecuado.\")\n    else:\n        sexagenary_year = (year - 4) % 60\n        element = elements[int((sexagenary_year % 10) / 2)]\n        animal = animals[int(sexagenary_year % 12)]\n\n        print(f\"A√±o: {year} / Zodiaco: {animal} de {element}\")\n\nchinese_zodiac(year)"
  },
  {
    "objectID": "posts/ruta-aprendizaje-python/index.html#pero-est√°-lleno-de-otros-cursos",
    "href": "posts/ruta-aprendizaje-python/index.html#pero-est√°-lleno-de-otros-cursos",
    "title": "Mi ruta de aprendizaje en Python",
    "section": "Pero est√° lleno de otros cursos‚Ä¶",
    "text": "Pero est√° lleno de otros cursos‚Ä¶\nEfectivamente. Python, al ser uno de los lenguajes m√°s famosos, est√° lleno de tutoriales, cursos, videos en YouTube y libros, tanto de pago como, en su mayor√≠a, gratuitos. Adem√°s, la documentaci√≥n oficial de Python es bastante buena.\nEntonces, ¬øQu√© aporta aprendiendopython a la comunidad?\nPrimero. Yo no lo llamar√≠a un curso. Porque no est√° dise√±ado para ser eso. Como te mencionaba antes, lo que estoy documentando es mi ruta de aprendizaje, no estoy haciendo un curso. Pero, a pesar de eso, puede cumplir esa funci√≥n, principalmente, pues me he dedicado bastante a explicar los conceptos, dar muchos ejemplos y no dar cosas por obvias. Me parece que muchos cursos fallan en eso. Explican cosas muy por encima y no se detienen a explicarlas de forma clara.\nPor otro lado, el ritmo no es muy r√°pido. No es como esos cursos que te prometen que en 4 horas aprendes a programar y puedes tener el trabajo de tus sue√±os. Eso es mucha fantas√≠a y te venden algo que no es as√≠. Como todo en la vida, si quieres lograr las metas, debes dedicarle mucho tiempo, ser perseverante y seguir adelante, a√∫n cuando las cosas no te salgan. Como ac√° estoy documentando mis estudios, puede que le dedique m√°s tiempo a algunos temas que a otros, o que sea repetitivo en varias ocasiones.\nSin embargo, esto es j√∫stamente lo que lo hace diferente y especial. Pues yo tambi√©n lo estoy estudiando, por lo que esa expereincia de estudio y descubrimiento es muy valiosa, cosa que no ocurre en cursos o libros, donde todo est√° maqueteado. Ac√° te comento cosas que me funcionan y las que no, te hablo desde mi experiencia. Esto lo hace una forma muy especial de aprender. Es como ir al cine a ver una pel√≠culay comentar con un amigo mas mejores escenas, fallas y opiniones. Esa es una experiencia mucho m√°s entretenida que solo ir al cine. Bueno, ac√° es lo mismo.\nOk.\nTe dejo cordialmente invtada/o a seguir el aprendizaje de Python conmigo.\nüëâ Recuerda visitar aprendiendopython.com\nNos vemos!!"
  },
  {
    "objectID": "posts/factores-en-r/index.html",
    "href": "posts/factores-en-r/index.html",
    "title": "Factores en R",
    "section": "",
    "text": "Hola!!\nHoy toca ver c√≥digo. Yeahhh!!! üòÅ\nEn mi experiencia, uno de los aspectos m√°s relvantes a la hora de trabajar con datos, es saber manejar los datos categ√≥ricos o factores.\nEn la vida nos topamos a cada instante con este tipo de datos. Cuando vamos al supermercado, compramos frutas, l√°cteos, verduras y carnes. O cuando revisamos planillas de personas, vemos distintos tipos de profesiones. Si revisamos datos por pa√≠ses, finalmente √©stos son categor√≠as. Las categor√≠as est√°n por todos lados.\nPor otro lado, el conocimiento de factores es un plus muy potente para analizar datos y realizar la exploraci√≥n de los mismos. Tambi√©n, para inteligencia artificial, el manejo de datos categ√≥ricos es muy relevante. Muchas veces el transformar datos cont√≠nuos en factores ayuda a mejorar el desempe√±o de los modelos predictivos y es parte del feature engineering, uno de los pasos b√°sicos previos antes del desarrollo de cualquier modelo de inteligencia artificial."
  },
  {
    "objectID": "posts/factores-en-r/index.html#carga-de-datos",
    "href": "posts/factores-en-r/index.html#carga-de-datos",
    "title": "Factores en R",
    "section": "Carga de datos",
    "text": "Carga de datos\nOk. Ya tenemos claro que, al analizar datos, debemos conocer m√©todos para trabajar con categor√≠as o factores.\nPara ello, R y su framework tidyverse nos ofrece forcats. Una librer√≠a especializada en el manejo de factores. Te recomiendo que revises la documentaci√≥n oficial del la librer√≠a.\nAhora revisaremos muchas de sus funciones y que te ser√°n de gran utilidad en el d√≠a a d√≠a.\nPara los ejemplos usar√© estos datos disponibles en Kaggle.\nPrimero cargamos las librer√≠as que usaremos:\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\nVeamos un poco los datos‚Ä¶\n\nhere::i_am(\"index.qmd\")\nsuicides <- read_csv2(\"master.csv\") |> \n  clean_names()\n\n\nglimpse(suicides)\n\nRows: 27,820\nColumns: 12\n$ country           <chr> \"Albania\", \"Albania\", \"Albania\", \"Albania\", \"Albania‚Ä¶\n$ year              <dbl> 1987, 1987, 1987, 1987, 1987, 1987, 1987, 1987, 1987‚Ä¶\n$ sex               <chr> \"male\", \"male\", \"female\", \"male\", \"male\", \"female\", ‚Ä¶\n$ age               <chr> \"15-24 years\", \"35-54 years\", \"15-24 years\", \"75+ ye‚Ä¶\n$ suicides_no       <dbl> 21, 16, 14, 1, 9, 1, 6, 4, 1, 0, 0, 0, 2, 17, 1, 14,‚Ä¶\n$ population        <dbl> 312900, 308000, 289700, 21800, 274300, 35600, 278800‚Ä¶\n$ suicides_100k_pop <chr> \"6.71\", \"5.19\", \"4.83\", \"4.59\", \"3.28\", \"2.81\", \"2.1‚Ä¶\n$ country_year      <chr> \"Albania1987\", \"Albania1987\", \"Albania1987\", \"Albani‚Ä¶\n$ hdi_for_year      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ gdp_for_year      <chr> \"2,156,624,900\", \"2,156,624,900\", \"2,156,624,900\", \"‚Ä¶\n$ gdp_per_capita    <dbl> 796, 796, 796, 796, 796, 796, 796, 796, 796, 796, 79‚Ä¶\n$ generation        <chr> \"Generation X\", \"Silent\", \"Generation X\", \"G.I. Gene‚Ä¶\n\n\n\nhead(suicides)\n\n# A tibble: 6 √ó 12\n  country  year sex    age       suici‚Ä¶¬π popul‚Ä¶¬≤ suici‚Ä¶¬≥ count‚Ä¶‚Å¥ hdi_f‚Ä¶‚Åµ gdp_f‚Ä¶‚Å∂\n  <chr>   <dbl> <chr>  <chr>       <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>  \n1 Albania  1987 male   15-24 ye‚Ä¶      21  312900 6.71    Albani‚Ä¶ <NA>    2,156,‚Ä¶\n2 Albania  1987 male   35-54 ye‚Ä¶      16  308000 5.19    Albani‚Ä¶ <NA>    2,156,‚Ä¶\n3 Albania  1987 female 15-24 ye‚Ä¶      14  289700 4.83    Albani‚Ä¶ <NA>    2,156,‚Ä¶\n4 Albania  1987 male   75+ years       1   21800 4.59    Albani‚Ä¶ <NA>    2,156,‚Ä¶\n5 Albania  1987 male   25-34 ye‚Ä¶       9  274300 3.28    Albani‚Ä¶ <NA>    2,156,‚Ä¶\n6 Albania  1987 female 75+ years       1   35600 2.81    Albani‚Ä¶ <NA>    2,156,‚Ä¶\n# ‚Ä¶ with 2 more variables: gdp_per_capita <dbl>, generation <chr>, and\n#   abbreviated variable names ¬π‚Äãsuicides_no, ¬≤‚Äãpopulation, ¬≥‚Äãsuicides_100k_pop,\n#   ‚Å¥‚Äãcountry_year, ‚Åµ‚Äãhdi_for_year, ‚Å∂‚Äãgdp_for_year"
  },
  {
    "objectID": "posts/factores-en-r/index.html#as_factor",
    "href": "posts/factores-en-r/index.html#as_factor",
    "title": "Factores en R",
    "section": "as_factor",
    "text": "as_factor\nEn este art√≠culo no realizaremos an√°lisis estad√≠sticos pensando en modelos de inteligencia artificial, que es lo cl√°sico que se realiza en Kaggle. Sino que veremos el uso de la librer√≠a forcats.\nRevisemos la variable age del dataset.\nEsta variable est√° definida como string. Es decir, como una cadena de caracteres.\n\nstr(suicides$age)\n\n chr [1:27820] \"15-24 years\" \"35-54 years\" \"15-24 years\" \"75+ years\" ...\n\n\nSi queremos realizar an√°lisis de este dataset, el tener esta variable como string no es buena idea. Parece m√°s razonable transformarlo a un factor. La librer√≠a forcats contiene la funci√≥n as_factor() que nos permite hacer eso.\n\nsuicides <- suicides |> \n  mutate(age = as_factor(age))\n\nVeamos nuevamente la estructura de la variable.\n\nstr(suicides$age)\n\n Factor w/ 6 levels \"15-24 years\",..: 1 2 1 3 4 3 2 4 5 6 ...\n\n\nOk. Ahora la variable ya no es de tipo string, sino que la hemos cambiado a tipo factor con 6 niveles. Es decir, tiene 6 categor√≠as. Ve√°moslas‚Ä¶\n\nlevels(suicides$age)\n\n[1] \"15-24 years\" \"35-54 years\" \"75+ years\"   \"25-34 years\" \"55-74 years\"\n[6] \"5-14 years\""
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_relevel",
    "href": "posts/factores-en-r/index.html#fct_relevel",
    "title": "Factores en R",
    "section": "fct_relevel",
    "text": "fct_relevel\nSi te fijas bien, el orden de las categor√≠as no est√° bien. Me refiero a que no sigue un orden ascendente o descendente, sino que est√° desordenado. Pues bien, podemos reordenarlos usando la funci√≥n fct_relevel().\n\nsuicides <- suicides |>\n  mutate(age = fct_relevel(age,\n                           \"5-14 years\",\n                           \"15-24 years\",\n                           \"25-34 years\",\n                           \"35-54 years\",\n                           \"55-74 years\",\n                           \"75+ years\"\n  ))\n\nlevels(suicides$age)\n\n[1] \"5-14 years\"  \"15-24 years\" \"25-34 years\" \"35-54 years\" \"55-74 years\"\n[6] \"75+ years\"  \n\n\nPara efectos demostrativos, usar√© el argumento after de fct_relevel() para reordenar una categor√≠a.\nAc√° har√© que ‚Äú5-14 years‚Äù quede despu√©s del √≠ndice 1 (recuerda que en R, el √≠ndice parte en 1).\n\nsuicides <- suicides |> \n  mutate(age = fct_relevel(age, \"5-14 years\", after = 1))\n\nlevels(suicides$age)\n\n[1] \"15-24 years\" \"5-14 years\"  \"25-34 years\" \"35-54 years\" \"55-74 years\"\n[6] \"75+ years\"  \n\n\nVolver√© a ordenarlo de forma correcta‚Ä¶\n\nsuicides <- suicides |> \n  mutate(age = fct_relevel(age, \"5-14 years\", after = 0))\n\nlevels(suicides$age)\n\n[1] \"5-14 years\"  \"15-24 years\" \"25-34 years\" \"35-54 years\" \"55-74 years\"\n[6] \"75+ years\""
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_reorder",
    "href": "posts/factores-en-r/index.html#fct_reorder",
    "title": "Factores en R",
    "section": "fct_reorder",
    "text": "fct_reorder\nEsta funci√≥n es muy √∫til para los gr√°ficos, ya que permite reordenar los factores de modo de ajustarlos a nuestros requerimientos y necesidades de la visualizaci√≥n.\nRealicemos un gr√°fico para Chile:\n\nsuicides |>\n  filter(\n    year == 2015,\n    country == \"Chile\"\n  ) |>\n  group_by(age) |>\n  summarise(suicides_total = sum(suicides_no)) |>\n  mutate(prop = suicides_total / sum(suicides_total)) |>\n  ggplot(aes(age, suicides_total,\n    fill = suicides_total\n  )) +\n  geom_col(show.legend = FALSE) +\n  labs(\n    title = \"Suicides in Chile\", subtitle = \"Year 2015\", y = \"Total Number of Suicides\",\n    x = \"Age\", fill = \"Number of Suicides\"\n  ) +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\nEste gr√°fico est√° adecuado. Es informativo para saber cu√°l es el grupo etario que presenta m√°s suicidios. F√≠jate que el eje y est√° ordenado por las categor√≠as de age. Pero quiz√°s sea m√°s interesante ordenar los datos por el total de suicidios por grupo.\nVeamos c√≥mo hacerlo usando fct_reorder.\n\nsuicides |>\n  filter(\n    year == 2015,\n    country == \"Chile\"\n  ) |>\n  group_by(age) |>\n  summarise(suicides_total = sum(suicides_no)) |>\n  mutate(prop = suicides_total / sum(suicides_total)) |>\n  ggplot(aes(fct_reorder(age, suicides_total), suicides_total,\n    fill = suicides_total\n  )) +\n  geom_col(show.legend = FALSE) +\n  labs(title = \"Suicides in Chile\", subtitle = \"Year 2015\", y = \"Total Number of Suicides\", x = \"Age\", fill = \"Number of Suicides\") +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\nEste orden deja m√°s claro la cantidad de suicidios por grupo etario y la proporci√≥n entre cada uno, a diferencia del gr√°fico anterior. F√≠jate en d√≥nde us√© fct_reorder. Podemos leerlo que deseamos que el eje x (primer par√°metro de aes) que corresponde a age, sea ordenado por suicides_total. Esto por defecto se ordena de mayor a menor (orden ascendente). Si deseamos hacerlo en orden descendente, debemos agregar el argumento .desc = TRUE al interior de fct_reoder.\n\nsuicides |>\n  filter(\n    year == 2015,\n    country == \"Chile\"\n  ) |>\n  group_by(age) |>\n  summarise(suicides_total = sum(suicides_no)) |>\n  mutate(prop = suicides_total / sum(suicides_total)) |>\n  ggplot(aes(fct_reorder(age, suicides_total, .desc = TRUE), suicides_total,\n    fill = suicides_total\n  )) +\n  geom_col(show.legend = FALSE) +\n  labs(title = \"Suicides in Chile\", subtitle = \"Year 2015\", y = \"Total Number of Suicides\", x = \"Age\", fill = \"Number of Suicides\") +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_explicit_na",
    "href": "posts/factores-en-r/index.html#fct_explicit_na",
    "title": "Factores en R",
    "section": "fct_explicit_na",
    "text": "fct_explicit_na\nPara explicar esta funcion, vamos a usar la variable hdi_for_year (Human Development Index) que contiene datos NA.\nCreamos algunas categor√≠as:\n\nsuicides <- suicides |>\n  mutate(\n    hdi_cat = case_when(\n      hdi_for_year >= 0.80 ~ \"Very High Development\",\n      hdi_for_year >= 0.70 ~ \"High Development\",\n      hdi_for_year >= 0.55 ~ \"Medium Development\",\n      hdi_for_year >= 0.35 ~ \"Low Development\",\n      hdi_for_year < 0.35 ~ \"Very Low Development\"\n    ),\n    hdi_cat = as_factor(hdi_cat)\n  )\n\nYa sabemos que la variable hdi_for_year tiene datos NA, por lo que la nueva variable que acabamos de crear tambi√©n deber√≠a tener datos NA¬¥s.\n\nsum(is.na(suicides$hdi_cat))\n\n[1] 19456\n\n\nPara trabajar con los datos, tenerlos como NA podr√≠a complicar los an√°lisis y algunas funciones aritm√©ticas no funcionar√≠an o ser√≠a m√°s dificil de interpretar.\n\nsuicides |>\n  filter(country == \"Chile\") |>\n  group_by(country, hdi_cat) |>\n  summarise(n = n())\n\n# A tibble: 4 √ó 3\n# Groups:   country [1]\n  country hdi_cat                   n\n  <chr>   <fct>                 <int>\n1 Chile   Medium Development       24\n2 Chile   High Development         36\n3 Chile   Very High Development    60\n4 Chile   <NA>                    252\n\n\nUna opci√≥n es usar fct_explicit_na para identificar los NA¬¥s y asignarle un valor a esa categor√≠a. Esto hace m√°s legible las tablas y los an√°lisis.\n\nsuicides <- suicides |>\n  mutate(hdi_cat = fct_explicit_na(hdi_cat, na_level = \"Missing\"))\n\nsuicides |>\n  filter(country == \"Chile\") |>\n  group_by(country, hdi_cat) |>\n  summarise(n = n())\n\n# A tibble: 4 √ó 3\n# Groups:   country [1]\n  country hdi_cat                   n\n  <chr>   <fct>                 <int>\n1 Chile   Medium Development       24\n2 Chile   High Development         36\n3 Chile   Very High Development    60\n4 Chile   Missing                 252"
  },
  {
    "objectID": "posts/factores-en-r/index.html#section",
    "href": "posts/factores-en-r/index.html#section",
    "title": "Factores en R",
    "section": "",
    "text": "fct_lump\nPodemos agrupar categor√≠as, seg√∫n necesidad. Retomemos la variable que creamos hdi_cat.\nOmitimos los datos NA¬¥s, mantenemos las 2 categor√≠as con mayor cantidad de datos y el resto las agrupamos en una nueva categor√≠a ‚ÄúAverage/Low Development‚Äù usando el argumento other_level.\n\nsuicides |>\n  na.omit() |>\n  mutate(hdi_lumped = fct_lump(hdi_cat, n = 2, other_level = \"Average/Low Development\")) |>\n  count(hdi_lumped) |>\n  mutate(prop = n / sum(n)) |>\n  arrange(desc(n))\n\n# A tibble: 3 √ó 3\n  hdi_lumped                  n  prop\n  <fct>                   <int> <dbl>\n1 Very High Development    3600 0.430\n2 High Development         2952 0.353\n3 Average/Low Development  1812 0.217\n\n\nAcabamos de mantener las 2 categor√≠as con m√°s datos ( n = 2), pero tamb√©n podemos usar una proporci√≥n para hacer esa segmentaci√≥n. Para ello, usamos el argumento prop.\nVeamos un ejemplo‚Ä¶\n\nsuicides |>\n  na.omit() |>\n  mutate(hdi_relevel = fct_lump(hdi_cat, prop = 0.2, other_level = \"Below Average\")) |>\n  count(hdi_relevel) |>\n  mutate(prop = round(n / sum(n), 3))\n\n# A tibble: 4 √ó 3\n  hdi_relevel               n  prop\n  <fct>                 <int> <dbl>\n1 Medium Development     1752 0.209\n2 High Development       2952 0.353\n3 Very High Development  3600 0.43 \n4 Below Average            60 0.007\n\n\nUsamos prop = 0.20 para indicar que cualquier categor√≠a con 20% o menos se indica como ‚ÄúBelow Average‚Äù."
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_infreq",
    "href": "posts/factores-en-r/index.html#fct_infreq",
    "title": "Factores en R",
    "section": "fct_infreq",
    "text": "fct_infreq\nEsta funci√≥n se usa junto a la librer√≠a ggplot2. Por ejemplo, para una gr√°fica de conteo de datos, esta funci√≥n permite ordenar por frecuencia.\nPrimero veamos sin usarla y luego us√°ndola.\n\nsuicides |> \n  na.omit() |> \n  add_count(hdi_cat) |> \n  ggplot(aes(hdi_cat)) +\n  geom_bar(stat = \"count\") +\n  labs(x = \"HDI Level\", y = \"Count\") +\n  theme_minimal() \n\n\n\n\n\nlevels(suicides$hdi_cat)\n\n[1] \"Medium Development\"    \"High Development\"      \"Very High Development\"\n[4] \"Low Development\"       \"Missing\"              \n\n\nComo te dar√°s cuenta, el gr√°fico anterior est√° ordenado por los niveles de las categor√≠as de hdi_cat ( y que no est√° ordenado adem√°s). Podemos usar fct_infreq para order las categor√≠as por frecuencia (por defecto, lo hace en orden descendente).\n\nsuicides |> \n  na.omit() |> \n  add_count(hdi_cat) |> \n  ggplot(aes(fct_infreq(hdi_cat))) +\n  geom_bar(stat = \"count\") +\n  labs(x = \"HDI Level\", y = \"Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_rev",
    "href": "posts/factores-en-r/index.html#fct_rev",
    "title": "Factores en R",
    "section": "fct_rev",
    "text": "fct_rev\nPodemos hacer lo mismo anterior, pero ordenarlos en forma ascendente. Para ellos usamos fct_rev.\n\nsuicides |> \n  na.omit() |> \n  add_count(hdi_cat) |> \n  ggplot(aes(fct_rev(fct_infreq(hdi_cat)))) +\n  geom_bar(stat = \"count\") +\n  labs(x = \"HDI Level\", y = \"Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_count",
    "href": "posts/factores-en-r/index.html#fct_count",
    "title": "Factores en R",
    "section": "fct_count",
    "text": "fct_count\nEsta funci√≥n nos permite contar los datos por cada nivel de las categor√≠as.\n\nfct_count(suicides$hdi_cat)\n\n# A tibble: 5 √ó 2\n  f                         n\n  <fct>                 <int>\n1 Medium Development     1752\n2 High Development       2952\n3 Very High Development  3600\n4 Low Development          60\n5 Missing               19456\n\n\nEsta funci√≥n reemplaza lo que podemos hacer con la combinaci√≥n de group_by y summarise. Es lo mismo, pero con menos l√≠neas de c√≥digo. Esto podr√≠a ser √∫til en algunos casos para ser m√°s productivo, pero se pierde legibildad, pues hay que saber qu√© hace exactamente fct_count. En cambio, la combinaci√≥n de funciones es m√°s expl√≠cita. Queda a tu criterio de programador cual usar.\n\nsuicides |> \n  group_by(hdi_cat) |> \n  summarise(n = n())\n\n# A tibble: 5 √ó 2\n  hdi_cat                   n\n  <fct>                 <int>\n1 Medium Development     1752\n2 High Development       2952\n3 Very High Development  3600\n4 Low Development          60\n5 Missing               19456"
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_unique",
    "href": "posts/factores-en-r/index.html#fct_unique",
    "title": "Factores en R",
    "section": "fct_unique",
    "text": "fct_unique\nEsta funci√≥n es similar a unique de la base de R. O sea, muestra los valores √∫nicos de una variable.\n\nfct_unique(suicides$hdi_cat) \n\n[1] Medium Development    High Development      Very High Development\n[4] Low Development       Missing              \n5 Levels: Medium Development High Development ... Missing\n\n\n\nunique(suicides$hdi_cat)\n\n[1] Missing               Medium Development    High Development     \n[4] Very High Development Low Development      \n5 Levels: Medium Development High Development ... Missing"
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_collapse",
    "href": "posts/factores-en-r/index.html#fct_collapse",
    "title": "Factores en R",
    "section": "fct_collapse",
    "text": "fct_collapse\nEsta funci√≥n nos permite crear un factor a partir de otros. Es decir, colapsarlos en otro (o agruparlos).\nPara revisar esta funci√≥n, ahora usaremos la variable generation. Crearemos 2 nuevas variables que contienen distintas categor√≠as.\n\nsuicides |> \n  mutate(generation = as_factor(generation)) |> \n  mutate(generations = fct_collapse(generation,\n    \"Older Generations\" = c(\"Silent\", \"G.I. Generation\", \"Boomers\"),\n    \"Younger Generations\" = c(\"Generation X\", \"Generation Z\", \"Millenials\")\n  )) |> \n  pull(generations) |> \n  levels()\n\n[1] \"Younger Generations\" \"Older Generations\""
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_other",
    "href": "posts/factores-en-r/index.html#fct_other",
    "title": "Factores en R",
    "section": "fct_other",
    "text": "fct_other\nEsta funci√≥n permite agrupar niveles, para compararlo con uno en especial. Para definir la categor√≠a que queremos mentener usamos el argumento keep y el resto se agrupa en other.\n\nsuicides |> \n  mutate(silent_against_other = fct_other(generation, keep = \"Silent\")) |> \n  pull(silent_against_other) |> \n  levels()\n\n[1] \"Silent\" \"Other\""
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_recode",
    "href": "posts/factores-en-r/index.html#fct_recode",
    "title": "Factores en R",
    "section": "fct_recode",
    "text": "fct_recode\nEsta funci√≥n permite recodificar un nivel. Es decir, asignarle un nuevo nombre a una categor√≠a. Esto tiene varias posibilidades, como hacer m√°s entendible una variable.\n\nsuicides |> \n  mutate(age_levels = fct_recode(age,\n                                 \"Child\" = \"5-14 years\",\n                                 \"Adolescent/Young Adult\"= \"15-24 years\",\n                                 \"Adult\" = \"25-34 years\",\n                                 \"Middle-Aged Adult\"= \"35-54 years\",\n                                 \"Older Adult\" = \"55-74 years\",\n                                 \"Senior\" = \"75+ years\")) |> \n  pull(age_levels) |> \n  levels()\n\n[1] \"Child\"                  \"Adolescent/Young Adult\" \"Adult\"                 \n[4] \"Middle-Aged Adult\"      \"Older Adult\"            \"Senior\""
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_reorder2",
    "href": "posts/factores-en-r/index.html#fct_reorder2",
    "title": "Factores en R",
    "section": "fct_reorder2",
    "text": "fct_reorder2\nEsta funci√≥n se aplica para los gr√°ficos, junto a ggplot2. Lo que hace es reordenar los valores en base a un atributo.\n\nsuicides |> \n  filter(country == \"Chile\") |> \n  group_by(year, age) |> \n  summarise(suicides_total = sum(suicides_no)) |> \n  ggplot(aes(year, suicides_total, colour = fct_reorder2(age, year, suicides_total))) +\n  geom_line(size = 2) + \n  labs(title = \"Suicides in Chile\",\n       y = \"Total Number of Suicides\",\n       x = \"Year\", colour = \"Age\") +\n  theme_minimal()\n\n\n\n\nMira lo que pasa si no usamos fct_reorder2. Las l√≠neas de la gr√°fica son las mismas obviamente, pero la leyenda cambia y los colores de √©stas tambi√©n. La leyenda aparece en el orden de las categor√≠as que ordenamos antes, pero en el gr√°fco anterior, se ordenan en base al √∫ltimo valor y por tanto, la leyenda coincide con el orden de las lineas. Eso hace que sea m√°s legible y f√°cil de interpretar.\n\nsuicides |> \n  filter(country == \"Chile\") |> \n  group_by(year, age) |> \n  summarise(suicides_total = sum(suicides_no)) |> \n  ggplot(aes(year, suicides_total, colour = age)) +\n  geom_line(size = 2) + \n  labs(title = \"Suicides in Chile\",\n       y = \"Total Number of Suicides\",\n       x = \"Year\", colour = \"Age\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_relabel",
    "href": "posts/factores-en-r/index.html#fct_relabel",
    "title": "Factores en R",
    "section": "fct_relabel",
    "text": "fct_relabel\nEsta funci√≥n permite modificar el nombre de los niveles.\n\nsuicides$age |> \n  fct_relabel(~ str_replace_all(.x, \"years\", \" \")) |> \n  head()\n\n[1] 15-24   35-54   15-24   75+     25-34   75+    \nLevels: 5-14   15-24   25-34   35-54   55-74   75+"
  },
  {
    "objectID": "posts/factores-en-r/index.html#fct_anon",
    "href": "posts/factores-en-r/index.html#fct_anon",
    "title": "Factores en R",
    "section": "fct_anon",
    "text": "fct_anon\nEsta funci√≥n permite anonimizar una variable categ√≥rica.\n\nsuicides |> \n  mutate(generation = as_factor(generation) |> \n  fct_anon()) |> \n  group_by(generation) |> \n  count()\n\n# A tibble: 6 √ó 2\n# Groups:   generation [6]\n  generation     n\n  <fct>      <int>\n1 1           6364\n2 2           2744\n3 3           4990\n4 4           5844\n5 5           6408\n6 6           1470\n\n\nSe puede agregar un prefijo a cada categor√≠a anonimizada:\n\nsuicides |> \n  mutate(generation = as_factor(generation) |> \n  fct_anon(\"x-\")) |> \n  group_by(generation) |> \n  count()\n\n# A tibble: 6 √ó 2\n# Groups:   generation [6]\n  generation     n\n  <fct>      <int>\n1 x-1         6408\n2 x-2         6364\n3 x-3         5844\n4 x-4         2744\n5 x-5         4990\n6 x-6         1470"
  },
  {
    "objectID": "posts/factores-en-r/index.html#finalmente",
    "href": "posts/factores-en-r/index.html#finalmente",
    "title": "Factores en R",
    "section": "Finalmente‚Ä¶",
    "text": "Finalmente‚Ä¶\nHemos revisado muchas de las funciones de la librer√≠a forcats, que como ves es bastante extensa. De hecho, no revisamos todas, hay varias m√°s, pero me parece que son muy espec√≠ficas y para casos muy puntuales. De todas formas, recuerda visitar la documentaci√≥n oficial para revisar m√°s detalles.\nComo puedes ver, el conocer alguna de estas funciones es de mucha utilidad para trabajar con datos categ√≥ricos. Y como siempre, recuerda practicar y practicar. No hay otra forma de que las cosas se te queden en la cabeza.\nNos vemos!!! üòÉ"
  },
  {
    "objectID": "posts/predeccion-titanic/index.html",
    "href": "posts/predeccion-titanic/index.html",
    "title": "¬øQui√©n sobrevivi√≥ en el Titanic?",
    "section": "",
    "text": "Bienvendo/a!! üòõ\nHoy vamos a hacer algo distinto. Vamos a tratar de predecir qui√©n sobrevive de los pasajeros del Titanic, usando inteligencia artificial.\nOjo. No voy a ser muy exhaustivo, ni tan profundo en el an√°lisis ni usar√© modelos de machine learning muy complejos, pues quiero que este art√≠culo te sirva como ejemplo de lo que se puede llegar a hacer y sea simple de seguir. En la vida real la cosa es un poco distinta. Generalmente, se realizan m√∫ltiples pruebas con muchos modelos y se van seleccionando en base a su desempe√±o (ya veremos qu√© significa esto). Por otro lado, los datos tienden a estar mucho m√°s sucios y el trabajo de limpieza es una de las actividades a la que m√°s se le dedica tiempo y esfuerzo.\nPara efectos de este art√≠culo, usarmos los datos de una competencia de Kaggle, en donde est√° un dataset (un conjunto de datos) sobre los pasajeros del Titanic, en donde se especifican algunas variables y quien sobrevivi√≥ o no. Puedes revisar los datos en el siguiente enlace."
  },
  {
    "objectID": "posts/predeccion-titanic/index.html#los-datos",
    "href": "posts/predeccion-titanic/index.html#los-datos",
    "title": "¬øQui√©n sobrevivi√≥ en el Titanic?",
    "section": "Los datos",
    "text": "Los datos\nComo te mencionada, los datos correponden a registros de pasajeros que se subieron en el Titanic. Si, el Titanic. Ese barco brit√°nico que naufrag√≥ en el oc√©ano Atl√°ntico durante la noche del 14 y la madrugada del 15 de abril de 1912, mientras realizaba su viaje inaugural desde Southampton a Nueva York, tras chocar con un iceberg. En el hundimiento la gran mayor√≠a de las personas que iban a bordo, lo que convierte a esta cat√°strofe en uno de los mayores naufragios de la historia.\nHay una pel√≠cula de como 4 horas donde sale Di Caprio, tambi√©n. La viste?\nOk. Ya sabemos de qu√© van los datos.\nLos datos incluyen 3 archivos:\n\ngender_submission.csv\ntest.csv\ntrain.csv\n\nEl primero es un ejemplo de c√≥mo se deben subir las predicciones a la web de Kaggle para participar de la competencia (Ah! La competencia tiene que ver con qui√©n logra acertar m√°s con las predicciones).\nEl archivo test contiene datos de los pasajeros para realizar las pruebas del modelo de machine learning. No contiene datos sobre la sobrevivencia. Son los registros que hay que predecir.\nEl archivo train contiene los datos de los pasajeros para realizar el entrenamiento del algoritmo de machine learninig. Este tiene especificado si el pasajero sobrevivi√≥ o no."
  },
  {
    "objectID": "posts/prediccion-titanic/index.html",
    "href": "posts/prediccion-titanic/index.html",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "",
    "text": "Bienvendo/a!! üòõ\nHoy vamos a hacer algo distinto. Vamos a tratar de predecir qui√©n sobrevive de los pasajeros del Titanic, usando inteligencia artificial.\nOjo. No voy a ser muy exhaustivo, ni tan profundo en el an√°lisis ni usar√© modelos de machine learning muy complejos, pues quiero que este art√≠culo te sirva como ejemplo de lo que se puede llegar a hacer y sea simple de seguir. En la vida real la cosa es un poco distinta. Generalmente, se realizan m√∫ltiples pruebas con muchos modelos y se van seleccionando en base a su desempe√±o (ya veremos qu√© significa esto). Por otro lado, los datos tienden a estar mucho m√°s sucios y el trabajo de limpieza es una de las actividades a la que m√°s se le dedica tiempo y esfuerzo.\nPara efectos de este art√≠culo, usarmos los datos de una competencia de Kaggle, en donde est√° un dataset (un conjunto de datos) sobre los pasajeros del Titanic, en donde se especifican algunas variables y quien sobrevivi√≥ o no. Puedes revisar los datos en el siguiente enlace."
  },
  {
    "objectID": "posts/prediccion-titanic/index.html#los-datos",
    "href": "posts/prediccion-titanic/index.html#los-datos",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "Los datos",
    "text": "Los datos\nComo te mencionada, los datos correponden a registros de pasajeros que se subieron en el Titanic. Si, el Titanic. Ese barco brit√°nico que naufrag√≥ en el oc√©ano Atl√°ntico durante la noche del 14 y la madrugada del 15 de abril de 1912, mientras realizaba su viaje inaugural desde Southampton a Nueva York, tras chocar con un iceberg. En el hundimiento la gran mayor√≠a de las personas que iban a bordo, lo que convierte a esta cat√°strofe en uno de los mayores naufragios de la historia.\nHay una pel√≠cula de como 4 horas donde sale Di Caprio, tambi√©n. La viste?\nOk. Ya sabemos de qu√© van los datos.\nLos datos incluyen 3 archivos:\n\ngender_submission.csv\ntest.csv\ntrain.csv\n\nEl primero es un ejemplo de c√≥mo se deben subir las predicciones a la web de Kaggle para participar de la competencia (Ah! La competencia tiene que ver con qui√©n logra acertar m√°s con las predicciones).\nEl archivo test contiene datos de los pasajeros para realizar las pruebas del modelo de machine learning. No contiene datos sobre la sobrevivencia. Son los registros que hay que predecir.\nEl archivo train contiene los datos de los pasajeros para realizar el entrenamiento del algoritmo de machine learninig. Este tiene especificado si el pasajero sobrevivi√≥ o no.\nVamos con el tema‚Ä¶\nCargamos las librer√≠as:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(here)\nlibrary(skimr)\nlibrary(janitor)\n\nCargamos los datos:\n\nhere::i_am(\"index.qmd\")\ntrain <- read_csv(\"train.csv\")\ntest <- read_csv(\"test.csv\")"
  },
  {
    "objectID": "posts/prediccion-titanic/index.html#an√°lisis-exploratorio",
    "href": "posts/prediccion-titanic/index.html#an√°lisis-exploratorio",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "An√°lisis exploratorio",
    "text": "An√°lisis exploratorio\nEsta etapa es fundamental. el an√°lisis exploratorio de datos es una de las primeras etapas en cualquier proyectos de ciencia de datos. El objetivo es analizar los datos para entender c√≥mo est√°n compuestos y qu√© representan. Habitualmente para estos fines, se pueden usar estad√≠sticas descriptivas e inferenciales. Adem√°s, el uso de visualizaciones es un elemento super valioso.\nPor lo dem√°s, de este an√°lisis exploratorio, se pueden desprender distintas acciones de Feature Engeneering. Este es un paso muy importante en el aprendizaje autom√°tico. El feature engineering (o ingenier√≠a de caracter√≠sticas) se refiere al proceso de dise√±o de caracter√≠sticas artificiales en un algoritmo. Estas caracter√≠sticas artificiales son utilizadas por ese algoritmo para mejorar su rendimiento y precisi√≥n.\nEste paso es fundamental en los modelos de machine learning. Aunque para efectos de este art√≠culo, posiblemente no har√© todo lo que se podr√≠a hacer, como expliqu√© al inicio, para privilegiar la comprensi√≥n m√°s que los resultados.\nYa que tenemos los datos, ahora veamos un poco de qu√© se tratan:\n\nstr(train)\n\nspec_tbl_df [891 √ó 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ PassengerId: num [1:891] 1 2 3 4 5 6 7 8 9 10 ...\n $ Survived   : num [1:891] 0 1 1 1 0 0 0 0 1 1 ...\n $ Pclass     : num [1:891] 3 1 3 1 3 3 1 3 3 2 ...\n $ Name       : chr [1:891] \"Braund, Mr. Owen Harris\" \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" \"Heikkinen, Miss. Laina\" \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" ...\n $ Sex        : chr [1:891] \"male\" \"female\" \"female\" \"female\" ...\n $ Age        : num [1:891] 22 38 26 35 35 NA 54 2 27 14 ...\n $ SibSp      : num [1:891] 1 1 0 1 0 0 0 3 0 1 ...\n $ Parch      : num [1:891] 0 0 0 0 0 0 0 1 2 0 ...\n $ Ticket     : chr [1:891] \"A/5 21171\" \"PC 17599\" \"STON/O2. 3101282\" \"113803\" ...\n $ Fare       : num [1:891] 7.25 71.28 7.92 53.1 8.05 ...\n $ Cabin      : chr [1:891] NA \"C85\" NA \"C123\" ...\n $ Embarked   : chr [1:891] \"S\" \"C\" \"S\" \"S\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   PassengerId = col_double(),\n  ..   Survived = col_double(),\n  ..   Pclass = col_double(),\n  ..   Name = col_character(),\n  ..   Sex = col_character(),\n  ..   Age = col_double(),\n  ..   SibSp = col_double(),\n  ..   Parch = col_double(),\n  ..   Ticket = col_character(),\n  ..   Fare = col_double(),\n  ..   Cabin = col_character(),\n  ..   Embarked = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\nstr(test)\n\nspec_tbl_df [418 √ó 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ PassengerId: num [1:418] 892 893 894 895 896 897 898 899 900 901 ...\n $ Pclass     : num [1:418] 3 3 2 3 3 3 3 2 3 3 ...\n $ Name       : chr [1:418] \"Kelly, Mr. James\" \"Wilkes, Mrs. James (Ellen Needs)\" \"Myles, Mr. Thomas Francis\" \"Wirz, Mr. Albert\" ...\n $ Sex        : chr [1:418] \"male\" \"female\" \"male\" \"male\" ...\n $ Age        : num [1:418] 34.5 47 62 27 22 14 30 26 18 21 ...\n $ SibSp      : num [1:418] 0 1 0 0 1 0 0 1 0 2 ...\n $ Parch      : num [1:418] 0 0 0 0 1 0 0 1 0 0 ...\n $ Ticket     : chr [1:418] \"330911\" \"363272\" \"240276\" \"315154\" ...\n $ Fare       : num [1:418] 7.83 7 9.69 8.66 12.29 ...\n $ Cabin      : chr [1:418] NA NA NA NA ...\n $ Embarked   : chr [1:418] \"Q\" \"S\" \"Q\" \"S\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   PassengerId = col_double(),\n  ..   Pclass = col_double(),\n  ..   Name = col_character(),\n  ..   Sex = col_character(),\n  ..   Age = col_double(),\n  ..   SibSp = col_double(),\n  ..   Parch = col_double(),\n  ..   Ticket = col_character(),\n  ..   Fare = col_double(),\n  ..   Cabin = col_character(),\n  ..   Embarked = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nPuedes notar que los 2 archivos son similares en su composici√≥n, excepto que train tiene la variable Survived y test no. Adem√°s, train contiene casi el doble de registros (filas) que test.\nEn Kaggle se explican qu√© significan los variables (diccionario) y ponen algunas notas. Estos datos son importantes para comprender el dataset y pensar en c√≥mo ajustarlos si es necesario. En todo proyecto de datos es muy relevante entender qu√© representan los datos y cu√°les son sus posibilidades.\nDiccionario:\n\n\n\n\n\nNotas:\n\n\n\n\n\nRevisemos las primeras filas de los datos:\n\nhead(train)\n\n# A tibble: 6 √ó 12\n  PassengerId Survived Pclass Name    Sex     Age SibSp Parch Ticket  Fare Cabin\n        <dbl>    <dbl>  <dbl> <chr>   <chr> <dbl> <dbl> <dbl> <chr>  <dbl> <chr>\n1           1        0      3 Braund‚Ä¶ male     22     1     0 A/5 2‚Ä¶  7.25 <NA> \n2           2        1      1 Cuming‚Ä¶ fema‚Ä¶    38     1     0 PC 17‚Ä¶ 71.3  C85  \n3           3        1      3 Heikki‚Ä¶ fema‚Ä¶    26     0     0 STON/‚Ä¶  7.92 <NA> \n4           4        1      1 Futrel‚Ä¶ fema‚Ä¶    35     1     0 113803 53.1  C123 \n5           5        0      3 Allen,‚Ä¶ male     35     0     0 373450  8.05 <NA> \n6           6        0      3 Moran,‚Ä¶ male     NA     0     0 330877  8.46 <NA> \n# ‚Ä¶ with 1 more variable: Embarked <chr>\n\n\n\nhead(test)\n\n# A tibble: 6 √ó 11\n  PassengerId Pclass Name     Sex     Age SibSp Parch Ticket  Fare Cabin Embar‚Ä¶¬π\n        <dbl>  <dbl> <chr>    <chr> <dbl> <dbl> <dbl> <chr>  <dbl> <chr> <chr>  \n1         892      3 Kelly, ‚Ä¶ male   34.5     0     0 330911  7.83 <NA>  Q      \n2         893      3 Wilkes,‚Ä¶ fema‚Ä¶  47       1     0 363272  7    <NA>  S      \n3         894      2 Myles, ‚Ä¶ male   62       0     0 240276  9.69 <NA>  Q      \n4         895      3 Wirz, M‚Ä¶ male   27       0     0 315154  8.66 <NA>  S      \n5         896      3 Hirvone‚Ä¶ fema‚Ä¶  22       1     1 31012‚Ä¶ 12.3  <NA>  S      \n6         897      3 Svensso‚Ä¶ male   14       0     0 7538    9.22 <NA>  S      \n# ‚Ä¶ with abbreviated variable name ¬π‚ÄãEmbarked\n\n\nVeamos m√°s cosas de los datos. Usaremos la librer√≠a skimr y su funci√≥n skim para explorar los datos y generar algunas primeras estad√≠sticas de las variables.\n\nskim(train)\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n‚ñá‚ñá‚ñá‚ñá‚ñá\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÖ\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñá\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n‚ñÇ‚ñá‚ñÖ‚ñÇ‚ñÅ\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\n\nskim(test)\n\n\nData summary\n\n\nName\ntest\n\n\nNumber of rows\n418\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n13\n63\n0\n418\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n363\n0\n\n\nCabin\n327\n0.22\n1\n15\n0\n76\n0\n\n\nEmbarked\n0\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.00\n1100.50\n120.81\n892.00\n996.25\n1100.50\n1204.75\n1309.00\n‚ñá‚ñá‚ñá‚ñá‚ñá\n\n\nPclass\n0\n1.00\n2.27\n0.84\n1.00\n1.00\n3.00\n3.00\n3.00\n‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñá\n\n\nAge\n86\n0.79\n30.27\n14.18\n0.17\n21.00\n27.00\n39.00\n76.00\n‚ñÇ‚ñá‚ñÉ‚ñÇ‚ñÅ\n\n\nSibSp\n0\n1.00\n0.45\n0.90\n0.00\n0.00\n0.00\n1.00\n8.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nParch\n0\n1.00\n0.39\n0.98\n0.00\n0.00\n0.00\n0.00\n9.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nFare\n1\n1.00\n35.63\n55.91\n0.00\n7.90\n14.45\n31.50\n512.33\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\nCon el an√°lisis anterior, nos damos cuenta que hay datos faltantes (missing data) o NA¬¥s. En particular, en la variable age, que es la que tiene una gran cantidad de NA¬¥s. Este dato es relevante, pues podr√≠a afectar bastante el algoritmo. Trabajar los datos faltantes es un √°rea muy importante, por lo que no podemos dejar pasar este hecho. Ya abordaremos esto m√°s adelante.\nPor ahora, dado que ambos set de datos son muy similares, los voy a unir para dejarlos en solo 1 objeto. Esto me ser√° √∫til para el an√°lisis y feature engineering de todo el conjunto. Luego lo dividir√© nuevamente para efectos del algoritmo.\n\nall_data <- bind_rows(list(\"train\" = train, \"test\" = test), .id = \"id\")\n\n\nglimpse(all_data)\n\nRows: 1,309\nColumns: 13\n$ id          <chr> \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"tra‚Ä¶\n$ PassengerId <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,‚Ä¶\n$ Survived    <dbl> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1‚Ä¶\n$ Pclass      <dbl> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3‚Ä¶\n$ Name        <chr> \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl‚Ä¶\n$ Sex         <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal‚Ä¶\n$ Age         <dbl> 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, ‚Ä¶\n$ SibSp       <dbl> 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0‚Ä¶\n$ Parch       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0‚Ä¶\n$ Ticket      <chr> \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37‚Ä¶\n$ Fare        <dbl> 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,‚Ä¶\n$ Cabin       <chr> NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C‚Ä¶\n$ Embarked    <chr> \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"‚Ä¶\n\n\n\nskim(all_data)\n\n\nData summary\n\n\nName\nall_data\n\n\nNumber of rows\n1309\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1.00\n4\n5\n0\n2\n0\n\n\nName\n0\n1.00\n12\n82\n0\n1307\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n929\n0\n\n\nCabin\n1014\n0.23\n1\n15\n0\n186\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.00\n655.00\n378.02\n1.00\n328.0\n655.00\n982.00\n1309.00\n‚ñá‚ñá‚ñá‚ñá‚ñá\n\n\nSurvived\n418\n0.68\n0.38\n0.49\n0.00\n0.0\n0.00\n1.00\n1.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÖ\n\n\nPclass\n0\n1.00\n2.29\n0.84\n1.00\n2.0\n3.00\n3.00\n3.00\n‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñá\n\n\nAge\n263\n0.80\n29.88\n14.41\n0.17\n21.0\n28.00\n39.00\n80.00\n‚ñÇ‚ñá‚ñÖ‚ñÇ‚ñÅ\n\n\nSibSp\n0\n1.00\n0.50\n1.04\n0.00\n0.0\n0.00\n1.00\n8.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nParch\n0\n1.00\n0.39\n0.87\n0.00\n0.0\n0.00\n0.00\n9.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nFare\n1\n1.00\n33.30\n51.76\n0.00\n7.9\n14.45\n31.27\n512.33\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\nF√≠jate que hice algo extra al unir los datos. Inclu√≠ una nueva variable id en donde se se√±ala si los registros son de test o train.\nVeamos cu√°ntas personas sobrevivieron (de los datos, que son una muestra de todos los pasajeros del Titanic, que eran m√°s de 2200 en total).\n\ntable(all_data$Survived)\n\n\n  0   1 \n549 342 \n\n\nLos datos clasificados como 0 no sobrevivieron y los 1; si. Podemos ver la misma tabla, pero en proporci√≥n.\n\nround(prop.table(table(all_data$Survived)), 4) * 100\n\n\n    0     1 \n61.62 38.38 \n\n\nVeamos si el sexo nos da alguna informaci√≥n importante.\n\ntable(all_data$Sex)\n\n\nfemale   male \n   466    843 \n\n\n\ntable(all_data$Sex, all_data$Survived)\n\n        \n           0   1\n  female  81 233\n  male   468 109\n\n\n\nall_data |> \n  filter(!is.na(Survived)) |> \n  mutate(Survived = factor(Survived)) |> \n  group_by(Sex, Survived) |> \n  summarise(n = n()) |> \n  ggplot(aes(Survived, n, fill = Survived)) +\n  geom_col(show.legend = FALSE)\n\n\n\n\n\nall_data |> \n  filter(!is.na(Survived)) |> \n  mutate(Survived = factor(Survived)) |> \n  group_by(Sex, Survived) |> \n  summarise(n = n()) |> \n  ggplot(aes(Survived, n, fill = Sex)) +\n  geom_col(position = \"dodge\")\n\n\n\n\n\nall_data |> \n  filter(Survived == 1) |> # Si sobreviven\n  tabyl(Sex)\n\n    Sex   n   percent\n female 233 0.6812865\n   male 109 0.3187135\n\n\n\nall_data |> \n  filter(Survived == 0) |> # No sobreviven\n  tabyl(Sex)\n\n    Sex   n  percent\n female  81 0.147541\n   male 468 0.852459\n\n\n\nall_data |> \n  filter(!is.na(Age)) |> \n  group_by(Sex) |> \n  summarise(mean = mean(Age))\n\n# A tibble: 2 √ó 2\n  Sex     mean\n  <chr>  <dbl>\n1 female  28.7\n2 male    30.6\n\n\n\nall_data |> \n  filter(!is.na(Age), !is.na(Survived)) |> \n  group_by(Sex, Survived) |> \n  summarise(mean = mean(Age))\n\n# A tibble: 4 √ó 3\n# Groups:   Sex [2]\n  Sex    Survived  mean\n  <chr>     <dbl> <dbl>\n1 female        0  25.0\n2 female        1  28.8\n3 male          0  31.6\n4 male          1  27.3\n\n\n\nall_data |> \n  filter(!is.na(Age), !is.na(Survived)) |> \n  ggplot(aes(Age, Sex)) +\n  geom_boxplot()\n\n\n\n\n\nall_data |> \n  filter(!is.na(Age), !is.na(Survived)) |> \n  ggplot(aes(Age, factor(Survived), fill = Sex)) +\n  geom_boxplot()\n\n\n\n\nRevisemos algo de los datos las clases:\n\nall_data |>\n  ggplot(aes(factor(Pclass), fill = factor(Pclass))) +\n  geom_bar() +\n  scale_fill_discrete(name = \"Class\", labels = c(\"1st\", \"2nd\", \"3rd\"))\n\n\n\n\n\nall_data |> \n  filter(!is.na(Survived)) |> \n  ggplot(aes(factor(Pclass), fill = factor(Survived))) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nAc√° aparece algo interesate. Las personas de tercera clase, en su mayor√≠a, no sobrevivieron. A diferencia de los de primera clase, donde hubo m√°s sobrevivientes que fallecidos (proporcionalmente).\nRevisemos el costo de los tickets.\n\nall_data |> \n  ggplot(aes(Fare)) + \n  geom_histogram(bins = 30)\n\n\n\n\n\nall_data |> \n  filter(!is.na(Survived)) |> \n  ggplot(aes(Fare, fill = factor(Survived))) + \n  geom_density(alpha = 0.6)\n\n\n\n\nEstos datos se√±alan en el mismo sentido de que las personas de clases m√°s altas y con tickets m√°s caros, sobrevivieron m√°s."
  },
  {
    "objectID": "posts/prediccion-titanic/index.html#manejo-de-nas",
    "href": "posts/prediccion-titanic/index.html#manejo-de-nas",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "Manejo de NA¬¥s",
    "text": "Manejo de NA¬¥s\nVolvamos un poco a revisar los datos faltantes (NA¬¥s).\n\nsummary(VIM::aggr(all_data))\n\n\n\n\n\n Missings per variable: \n    Variable Count\n          id     0\n PassengerId     0\n    Survived   418\n      Pclass     0\n        Name     0\n         Sex     0\n         Age   263\n       SibSp     0\n       Parch     0\n      Ticket     0\n        Fare     1\n       Cabin  1014\n    Embarked     2\n\n Missings in combinations of variables: \n              Combinations Count     Percent\n 0:0:0:0:0:0:0:0:0:0:0:0:0   183 13.98013751\n 0:0:0:0:0:0:0:0:0:0:0:0:1     2  0.15278839\n 0:0:0:0:0:0:0:0:0:0:0:1:0   529 40.41252865\n 0:0:0:0:0:0:1:0:0:0:0:0:0    19  1.45148969\n 0:0:0:0:0:0:1:0:0:0:0:1:0   158 12.07028266\n 0:0:1:0:0:0:0:0:0:0:0:0:0    87  6.64629488\n 0:0:1:0:0:0:0:0:0:0:0:1:0   244 18.64018335\n 0:0:1:0:0:0:0:0:0:0:1:1:0     1  0.07639419\n 0:0:1:0:0:0:1:0:0:0:0:0:0     4  0.30557678\n 0:0:1:0:0:0:1:0:0:0:0:1:0    82  6.26432391\n\n\nYa lo hab√≠amos visto antes. Los registros tienen bastantes datos faltantes (missing data). Estos datos se presentan especialmente en las variables Age y Cabin. Survived tienen muchos NA¬¥s, pues unimos los regitros al inicio por temas metodol√≥gicos, pero ac√° no tiene relevancia.\nAc√° tenemos un tema muy relevante en proyectos de datos y es el manejar los datos faltantes y tomar decisiones al respecto. En este art√≠culo no profundizar√© demasiado en este tema, pues se escapa del objetivo de ser m√°s demostrativo. Pero es un √°rea relevante de estudio que posiblemente aborde en otro art√≠culo m√°s adelante.\nEn este caso, tomar√© 2 decisiones. Con respecto a la variable Cabin no la considar√© para el desarrollo y entrenamiento del algoritmo, pues tiene un porcentaje muy alto de p√©rdida y adaptarlo a algo √∫til parece ser poco factible, en un primer momento. Con la variable Age pasa algo distinto, pues parece tener m√°s relevancia en la probabilidad de sobrevivir.\nEntonces, haremos algo para completar esos datos. Una alternativa es imputar datos. Es decir, asumir la edad en base a algunos supuestos. Existen varias metodolog√≠as como calcular la media o mediana de todos los datos de edad y pon√©rselo a los NA¬¥s. Otro m√©todo es aplicar algoritmos de machine learning para predecir ese dato e imputarlo.\nVeamos algunos datos de la edad:\n\nsummary(all_data$Age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.17   21.00   28.00   29.88   39.00   80.00     263 \n\n\n\nall_data |> \n  ggplot(aes(Age)) +\n  geom_histogram()\n\n\n\n\nDebido a que la distribuci√≥n de la edad se acerca a una distribuci√≥n normal (histograma) y a que la media y mediana se a cercan bastante, podriamos usar el primer enfoque de amputaci√≥n, que es usar la mediana para completar los datos faltantes. Te recuerdo que este es solo un enfoque posible. En proyectos reales, lo que se hace es probar muchos modelos y m√©todos y analizar su desempe√±o. Insisto, para efectos de este art√≠culo, usar√© este acercamiento.\nVerifiquemos las normalidad de los datos de edad. Primero, realizaremos un gr√°fico QQ plot, el cual consiste en comparar los cuantiles de la distribuci√≥n observada con los cuantiles te√≥ricos de una distribuci√≥n normal con la misma media y desviaci√≥n est√°ndar que los datos. En la medida que los datos se ajusten a la l√≠nea proyectada, m√°s se aproximan a una distribuci√≥n normal.\nAplicar√© la funci√≥n lillie.test de la librer√≠a nortest para usar el test de Lilliefors. Este test nace con la idea de resolver uno de los problemas del test Kolmogorov-Smirnov que es al no conocer la media y la varianza poblacional, tiene poca potencia estad√≠stica. El test Lilliefors asume que la media y varianza son desconocidas y es especialmente √∫til en muestras grandes.\n\nqqnorm(all_data$Age, pch = 19, col = \"gray50\")\nqqline(all_data$Age)\n\n\n\n\n\nnortest::lillie.test(all_data$Age)\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  all_data$Age\nD = 0.078928, p-value < 2.2e-16\n\n\nVemos que tanto QQ plot y el test Lilliefors apuntan a que los datos tienen una distribuci√≥n normal.\nVolvamos a ver los datos, separados por sexo:\n\nall_data |> \n  ggplot(aes(Age)) +\n  geom_histogram() +\n  facet_grid(~ Sex)\n\n\n\n\nImputaci√≥n de datos.\nPodr√≠amos imputar los datos faltantes usando las siguientes l√≠neas de c√≥digo.\n\nall_data$Age[is.na(all_data$Age)] <- median(all_data$Age, na.rm = TRUE)\nall_data$Fare[is.na(all_data$Fare)] <- mean(all_data$Fare, na.rm = TRUE)\nall_data$Embarked[is.na(all_data$Embarked)] <- mode(all_data$Embarked)"
  },
  {
    "objectID": "posts/prediccion-titanic/index.html#feature-engineering",
    "href": "posts/prediccion-titanic/index.html#feature-engineering",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nEl dataset tiene algunas variables que son de dudosa ayuda para predecir y generar el algoritmo, al menos, a priori. Casi por sentido com√∫n. A√∫n cuando tomar decisiones por sentido com√∫n podr√≠a no ser la mejor alternativa, muchas veces nos equivocamos o traspasamos nuestros sesgos a los an√°lisis. La idea siempre es tratar de dejar que ‚Äúlos datos hablen‚Äù. En este caso, como es un art√≠culo m√°s referencial, no profundizar√© en la generaci√≥n y manipulaci√≥n de las variables para no confundir tanto, pero si har√© un par de cosas que me parecen interesantes y que muestra las posibilidades del feature engineering.\nLas variables Ticket, Name y Cabin parecen ser datos poco informativos para saber si alguien sobrevivi√≥ o no al accidente. Sin embargo, no ser√≠a tan as√≠. Es posible que la cabina tenga alguna relaci√≥n con la sobrevivencia, quiz√°s por cercan√≠a a un pasillo o algo as√≠. El n¬∞ de ticket tambi√©n quiz√°s se asocia a algo, no lo sabemos, es necesario investigar. Que como ya te mencion√©, no lo haremos en esta ocasi√≥n jaja üòÑ\nPero si revisemos un poco m√°s el nombre de los pasajeros. Si revisas, el registro contiene el nombre de la personas y su t√≠tulo (Mr, Miss, Dr, Col, etc). Ese dato podr√≠a ser √∫til para la predicci√≥n. Quiz√°s hab√≠a alg√∫n tipo de jerarqu√≠a que favoreciera que se salvaran. Tambi√©n el apellido de las personas podr√≠a ser √∫til, m√°s que nada por temas de agrupar a familias.\nEntonces, crearemos 2 nuevas variables: Title y Surname. Para ello, usaremos la funci√≥n mutate y nos ayudaremos de las REGEX (expresiones regulares) para extraer los datos desde el nombre.\nConsejo: aprende REGEX. Es una gran herramienta en el an√°lisis de datos y aplica no solo para programaci√≥n en R, sino que para cualquier otro. Incluso se usa en navegadores web, email y diversas aplicaciones.\n\nall_data <- all_data |>\n  mutate(\n    Title = str_extract(Name, \"(?<=,[:space:])(.*?)[.]\"),\n    Surname = str_extract(Name, \".*(?=[,])\")\n  )\n\nVeamos como nos quedaron los datos‚Ä¶\n\nall_data |> \n  head()\n\n# A tibble: 6 √ó 15\n  id    Passen‚Ä¶¬π Survi‚Ä¶¬≤ Pclass Name  Sex     Age SibSp Parch Ticket  Fare Cabin\n  <chr>    <dbl>   <dbl>  <dbl> <chr> <chr> <dbl> <dbl> <dbl> <chr>  <dbl> <chr>\n1 train        1       0      3 Brau‚Ä¶ male     22     1     0 A/5 2‚Ä¶  7.25 <NA> \n2 train        2       1      1 Cumi‚Ä¶ fema‚Ä¶    38     1     0 PC 17‚Ä¶ 71.3  C85  \n3 train        3       1      3 Heik‚Ä¶ fema‚Ä¶    26     0     0 STON/‚Ä¶  7.92 <NA> \n4 train        4       1      1 Futr‚Ä¶ fema‚Ä¶    35     1     0 113803 53.1  C123 \n5 train        5       0      3 Alle‚Ä¶ male     35     0     0 373450  8.05 <NA> \n6 train        6       0      3 Mora‚Ä¶ male     28     0     0 330877  8.46 <NA> \n# ‚Ä¶ with 3 more variables: Embarked <chr>, Title <chr>, Surname <chr>, and\n#   abbreviated variable names ¬π‚ÄãPassengerId, ¬≤‚ÄãSurvived\n\n\n\nunique(all_data$Title)\n\n [1] \"Mr.\"           \"Mrs.\"          \"Miss.\"         \"Master.\"      \n [5] \"Don.\"          \"Rev.\"          \"Dr.\"           \"Mme.\"         \n [9] \"Ms.\"           \"Major.\"        \"Lady.\"         \"Sir.\"         \n[13] \"Mlle.\"         \"Col.\"          \"Capt.\"         \"the Countess.\"\n[17] \"Jonkheer.\"     \"Dona.\"        \n\n\nPodemos ampliar la variable Sex en base a los t√≠tulos. En especial, agregar algo que identifique a los ni√±os. Si te fijaste, los sobrevivientes son en general m√°s j√≥venes. Adem√°s, existe esta frase t√≠pica de salvar a los ni√±os y las mujeres primero. No tengo claro si eso es tan real, pero podr√≠a serlo. As√≠ que agreguemos la posibilidad.\n\nMan <- c(\n  \"Mr.\", \"Sir.\", \"Don.\", \"Rev.\", \"Major.\",\n  \"Col.\", \"Capt.\", \"Jonkheer.\",\n  \"Dr.\", \"Nobel.\"\n)\nFemale <- c(\"Mrs.\", \"Miss.\", \"Mme.\", \"Ms.\", \"Lady.\", \"Mlle.\", \"the Countess.\", \"Dona.\")\nBoy <- c(\"Master.\")\n\nall_data <- all_data |>\n  rowwise() |>\n  mutate(\n    Sex =\n      case_when(\n        (Title %in% Man) ~ \"Man\",\n        (Title %in% Female) ~ \"Female\",\n        (Title %in% Boy) ~ \"Boy\",\n        TRUE ~ Title\n      )\n  )\n\nRevisemos c√≥mo quedan los grupos con esta nueva clasificaci√≥n:\n\nall_data |> \n  filter(!is.na(Survived)) |> \n  tabyl(Sex, Survived)\n\n    Sex   0   1\n    Boy  17  23\n Female  81 232\n    Man 451  87\n\n\n\nall_data |> \n  filter(!is.na(Survived)) |> \n  mutate(Survived = factor(Survived)) |> \n  group_by(Sex, Survived) |> \n  summarise(n = n()) |> \n  ggplot(aes(Sex, n, fill = Survived)) +\n  geom_col(position = \"dodge\")\n\n\n\n\nAhora vamos a crear una nueva variable, que es el tama√±o de la familia. Para eso, sumaremos las variables SibSp (n¬∞ de hermanos y esposas/os) y Parch (n¬∞ de hijos y padres). A la suma le agregamos 1, pues agregamos al mismo pasajero al grupo familiar.\n\nall_data <- all_data |>\n  mutate(\n    Family_size = as.numeric(SibSp) + as.numeric(Parch) + 1,\n    Family_type = factor(ifelse(Family_size == 1, \"Single\",\n      ifelse(Family_size <= 3, \"Small\", \"Large\")\n    ))\n  ) |> \n  unnest(cols = c())\n\nRevisemos nuevamente los datos faltantes. Esto es importante, pues muchos modelos de machine learning no soportan variables con NA¬¥s o pueden alterar las predicciones.\n\nsummary(VIM::aggr(all_data))\n\n\n\n\n\n Missings per variable: \n    Variable Count\n          id     0\n PassengerId     0\n    Survived   418\n      Pclass     0\n        Name     0\n         Sex     0\n         Age     0\n       SibSp     0\n       Parch     0\n      Ticket     0\n        Fare     0\n       Cabin  1014\n    Embarked     0\n       Title     0\n     Surname     0\n Family_size     0\n Family_type     0\n\n Missings in combinations of variables: \n                      Combinations Count   Percent\n 0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0   204 15.584416\n 0:0:0:0:0:0:0:0:0:0:0:1:0:0:0:0:0   687 52.482811\n 0:0:1:0:0:0:0:0:0:0:0:0:0:0:0:0:0    91  6.951872\n 0:0:1:0:0:0:0:0:0:0:0:1:0:0:0:0:0   327 24.980901\n\n\nPor ahora, voy a dejar el an√°lisis exploratorio hasta ac√°. Podr√≠amos estar mucho tiempo m√°s revisando y d√°ndole vueltas al tema, pero creo que con lo que hemos visto ya te has hecho una buena idea de qu√© va √©sto.\nHabitualmente, los proyecto de Ciencia de Datos destinan cerca del 80% del tiempo en este tipo de actividades."
  },
  {
    "objectID": "posts/prediccion-titanic/index.html#modelamiento-ml",
    "href": "posts/prediccion-titanic/index.html#modelamiento-ml",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "Modelamiento ML",
    "text": "Modelamiento ML\nPara el modelamiento del algoritmo de machine learning (ML) usaremos la librer√≠a H2O.\nH2O funciona bastante distinto que otras librer√≠as, pues lo que hace es levantar un servidor y nos conoctamos a √©l, y es en ese servidor donde se ejecutan los algoritmos. H2O es una plataforma de autoML o de modelos de machine learning pre-entrenados. En palabras simples, la configuraci√≥n de los algoritmos viene ya lista ‚Äúde f√°brica‚Äù. En palabras m√°s complejas, los modelos de autoML ajustan el tuneo de los hiperpar√°metros de forma autom√°tica o ya cuentan con valores predefinidos.\n\n# Separamos el dataset para los datos de entrenamiento\ntitanic_train <- all_data |>\n  filter(id == \"train\") |>\n  select(-c(id, PassengerId, Name, Ticket, Cabin))\n\nAnalicemos los tipos de datos de titanic_train:\n\nstr(titanic_train)\n\ntibble [891 √ó 12] (S3: tbl_df/tbl/data.frame)\n $ Survived   : num [1:891] 0 1 1 1 0 0 0 0 1 1 ...\n $ Pclass     : num [1:891] 3 1 3 1 3 3 1 3 3 2 ...\n $ Sex        : chr [1:891] \"Man\" \"Female\" \"Female\" \"Female\" ...\n $ Age        : num [1:891] 22 38 26 35 35 28 54 2 27 14 ...\n $ SibSp      : num [1:891] 1 1 0 1 0 0 0 3 0 1 ...\n $ Parch      : num [1:891] 0 0 0 0 0 0 0 1 2 0 ...\n $ Fare       : num [1:891] 7.25 71.28 7.92 53.1 8.05 ...\n $ Embarked   : chr [1:891] \"S\" \"C\" \"S\" \"S\" ...\n $ Title      : chr [1:891] \"Mr.\" \"Mrs.\" \"Miss.\" \"Mrs.\" ...\n $ Surname    : chr [1:891] \"Braund\" \"Cumings\" \"Heikkinen\" \"Futrelle\" ...\n $ Family_size: num [1:891] 2 2 1 2 1 1 1 5 3 2 ...\n $ Family_type: Factor w/ 3 levels \"Small\",\"Single\",..: 1 1 2 1 2 2 2 3 1 1 ...\n\n\nCambiaremos algunos tipos de datos por algo m√°s √∫til.\n\ntitanic_train <- titanic_train |>\n  mutate(\n    Survived = factor(Survived),\n    Pclass = factor(Pclass),\n    Sex = factor(Sex),\n    Embarked = factor(Embarked),\n    Title = factor(Title)\n  )\n\nOk. Tenemos nuestros datos de entrenamiento listos o, al menos, m√°s preparados para ser analizados.\n\n# Cargamos la librer√≠a de H2O\nlibrary(h2o)\n\n# Creaci√≥n de un cluster local con todos los cores disponibles\nh2o.init(\n  ip = \"localhost\",\n  # -1 indica que se empleen todos los cores disponibles\n  nthreads = -1,\n  # M√°xima memoria disponible para el cluster\n  max_mem_size = \"3g\"\n)\n\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\pvill\\AppData\\Local\\Temp\\RtmpIffI42\\file5c1c27484d8d/h2o_pvill_started_from_r.out\n    C:\\Users\\pvill\\AppData\\Local\\Temp\\RtmpIffI42\\file5c1c3c976d3e/h2o_pvill_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         2 seconds 801 milliseconds \n    H2O cluster timezone:       America/Santiago \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.36.1.2 \n    H2O cluster version age:    4 months and 14 days !!! \n    H2O cluster name:           H2O_started_from_R_pvill_ufb539 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   2.98 GB \n    H2O cluster total cores:    16 \n    H2O cluster allowed cores:  16 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.2.1 (2022-06-23 ucrt) \n\n# Se eliminan los datos del cluster por si ya hab√≠a sido iniciado\nh2o.removeAll()\n\n# Para que no se muestre la barra de progreso\nh2o.no_progress()\n\n\ntitanic_h2o = as.h2o(titanic_train)\n\nPara nuestro caso, aplicaremos autoML o machine learning automatizado.\nEn la documentaci√≥n oficial de H2O puedes ver m√°s detalles.\nVamos al tema y veamos c√≥mo se podr√≠a implementar una soluci√≥n simple de autoML.\n\n# Separaci√≥n de las observaciones en conjunto de entrenamiento y test\nsplits <- h2o.splitFrame(data = titanic_h2o, ratios = 0.8, seed = 123)\ntitanic_train_h2o <- splits[[1]]\ntitanic_test_h2o  <- splits[[2]]\n\n# Se define la variable respuesta y los predictores\nresponse <- \"Survived\"\n\n# Para este modelo se emplean todos los predictores disponibles\npredictors  <- setdiff(h2o.colnames(titanic_h2o), response)\n\n# Ejectutamos 20 modelos de autoML\naml <- h2o.automl(\n  x = predictors, y = response,\n  training_frame = titanic_train_h2o,\n  max_models = 20,\n  seed = 123\n)\n\n\n22:00:07.918: AutoML: XGBoost is not available; skipping it.\n22:00:07.948: _train param, Dropping bad and constant columns: [Surname]\n22:00:09.7: _train param, Dropping bad and constant columns: [Surname]\n22:00:09.834: _train param, Dropping bad and constant columns: [Surname]\n22:00:11.678: _train param, Dropping bad and constant columns: [Surname]\n22:00:14.686: _train param, Dropping bad and constant columns: [Surname]\n22:00:15.69: _train param, Dropping bad and constant columns: [Surname]\n22:00:15.384: _train param, Dropping bad and constant columns: [Surname]\n22:00:15.918: _train param, Dropping bad and constant columns: [Surname]\n22:00:16.213: _train param, Dropping bad and constant columns: [Surname]\n22:03:33.246: _train param, Dropping unused columns: [Surname]\n22:03:33.966: _train param, Dropping unused columns: [Surname]\n\n\n\n# Ver autoML Leaderboard\nlb <- aml@leaderboard\nprint(lb, n = nrow(lb)) \n\n                                                  model_id       auc   logloss\n1                           XRT_1_AutoML_1_20221010_220007 0.8709619 0.4280390\n2  StackedEnsemble_BestOfFamily_1_AutoML_1_20221010_220007 0.8705471 0.4134399\n3                           GBM_2_AutoML_1_20221010_220007 0.8684124 0.4212379\n4                           GBM_4_AutoML_1_20221010_220007 0.8644931 0.4242718\n5              GBM_grid_1_AutoML_1_20221010_220007_model_3 0.8636030 0.4252027\n6              GBM_grid_1_AutoML_1_20221010_220007_model_1 0.8635338 0.4239069\n7     StackedEnsemble_AllModels_1_AutoML_1_20221010_220007 0.8633567 0.4180044\n8                           GBM_5_AutoML_1_20221010_220007 0.8622764 0.4245518\n9                           GLM_1_AutoML_1_20221010_220007 0.8607726 0.4308457\n10             GBM_grid_1_AutoML_1_20221010_220007_model_4 0.8603405 0.4310881\n11                          GBM_3_AutoML_1_20221010_220007 0.8595238 0.4300964\n12                          DRF_1_AutoML_1_20221010_220007 0.8591176 0.4954942\n13             GBM_grid_1_AutoML_1_20221010_220007_model_5 0.8572120 0.4396899\n14                 DeepLearning_1_AutoML_1_20221010_220007 0.8554533 0.4421416\n15                          GBM_1_AutoML_1_20221010_220007 0.8477487 0.4579601\n16             GBM_grid_1_AutoML_1_20221010_220007_model_2 0.8461974 0.4603829\n17    DeepLearning_grid_1_AutoML_1_20221010_220007_model_1 0.8459338 0.4700233\n18    DeepLearning_grid_3_AutoML_1_20221010_220007_model_2 0.8442010 0.4643837\n19    DeepLearning_grid_3_AutoML_1_20221010_220007_model_1 0.8430386 0.4639954\n20    DeepLearning_grid_2_AutoML_1_20221010_220007_model_1 0.8421658 0.5036609\n21    DeepLearning_grid_2_AutoML_1_20221010_220007_model_2 0.8417077 0.4876815\n22    DeepLearning_grid_1_AutoML_1_20221010_220007_model_2 0.8367168 0.4939174\n       aucpr mean_per_class_error      rmse       mse\n1  0.8346343            0.1859390 0.3661840 0.1340907\n2  0.8431666            0.1848025 0.3583348 0.1284039\n3  0.8327107            0.1849797 0.3617789 0.1308840\n4  0.8276144            0.1848846 0.3614534 0.1306485\n5  0.8311913            0.1859260 0.3635181 0.1321454\n6  0.8353353            0.1885360 0.3626827 0.1315388\n7  0.8405026            0.1884539 0.3599988 0.1295991\n8  0.8292195            0.1808141 0.3626516 0.1315162\n9  0.8366766            0.2003414 0.3684605 0.1357631\n10 0.8290372            0.1826938 0.3667785 0.1345264\n11 0.8246865            0.1873866 0.3651803 0.1333567\n12 0.8311538            0.1900095 0.3704124 0.1372053\n13 0.8172740            0.1861291 0.3691785 0.1362927\n14 0.8239047            0.2093596 0.3734248 0.1394461\n15 0.8225336            0.2232089 0.3811518 0.1452767\n16 0.8238082            0.2195575 0.3818452 0.1458057\n17 0.8146578            0.2207329 0.3826731 0.1464387\n18 0.8205795            0.2111875 0.3775377 0.1425347\n19 0.8131408            0.1991919 0.3781846 0.1430236\n20 0.7876542            0.2118356 0.3902014 0.1522571\n21 0.8254982            0.1996111 0.3762526 0.1415660\n22 0.8212612            0.1992049 0.3808260 0.1450284\n\n[22 rows x 7 columns] \n\n\n\n# Podemos revisar el modelo ganador\naml@leader\n\nModel Details:\n==============\n\nH2OBinomialModel: drf\nModel ID:  XRT_1_AutoML_1_20221010_220007 \nModel Summary: \n  number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n1              33                       33               39118        13\n  max_depth mean_depth min_leaves max_leaves mean_leaves\n1        20   17.72727         42        137    89.30303\n\n\nH2OBinomialMetrics: drf\n** Reported on training data. **\n** Metrics reported on Out-Of-Bag training samples **\n\nMSE:  0.1491174\nRMSE:  0.3861573\nLogLoss:  0.5119568\nMean Per-Class Error:  0.2038026\nAUC:  0.8463313\nAUCPR:  0.8090878\nGini:  0.6926627\nR^2:  0.3667232\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         0   1    Error      Rate\n0      346  89 0.204598   =89/435\n1       54 212 0.203008   =54/266\nTotals 400 301 0.203994  =143/701\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.437500   0.747795 179\n2                       max f2  0.378927   0.795292 202\n3                 max f0point5  0.755055   0.782353  73\n4                 max accuracy  0.651129   0.803138 103\n5                max precision  0.879121   0.963855  37\n6                   max recall  0.026050   1.000000 393\n7              max specificity  1.000000   0.997701   0\n8             max absolute_mcc  0.459596   0.585658 169\n9   max min_per_class_accuracy  0.437500   0.795402 179\n10 max mean_per_class_accuracy  0.459596   0.796413 169\n11                     max tns  1.000000 434.000000   0\n12                     max fns  1.000000 250.000000   0\n13                     max fps  0.000000 435.000000 399\n14                     max tps  0.026050 266.000000 393\n15                     max tnr  1.000000   0.997701   0\n16                     max fnr  1.000000   0.939850   0\n17                     max fpr  0.000000   1.000000 399\n18                     max tpr  0.026050   1.000000 393\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n\nH2OBinomialMetrics: drf\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.1340907\nRMSE:  0.366184\nLogLoss:  0.428039\nMean Per-Class Error:  0.185939\nAUC:  0.8709619\nAUCPR:  0.8346343\nGini:  0.7419238\nR^2:  0.4305393\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         0   1    Error      Rate\n0      355  80 0.183908   =80/435\n1       50 216 0.187970   =50/266\nTotals 405 296 0.185449  =130/701\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.418827   0.768683 202\n2                       max f2  0.274074   0.821104 257\n3                 max f0point5  0.628670   0.789720 135\n4                 max accuracy  0.497812   0.823110 180\n5                max precision  1.000000   1.000000   0\n6                   max recall  0.046593   1.000000 394\n7              max specificity  1.000000   1.000000   0\n8             max absolute_mcc  0.496049   0.624389 181\n9   max min_per_class_accuracy  0.418827   0.812030 202\n10 max mean_per_class_accuracy  0.418827   0.814061 202\n11                     max tns  1.000000 435.000000   0\n12                     max fns  1.000000 263.000000   0\n13                     max fps  0.023070 435.000000 399\n14                     max tps  0.046593 266.000000 394\n15                     max tnr  1.000000   1.000000   0\n16                     max fnr  1.000000   0.988722   0\n17                     max fpr  0.023070   1.000000 399\n18                     max tpr  0.046593   1.000000 394\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n                             mean       sd cv_1_valid cv_2_valid cv_3_valid\naccuracy                 0.830233 0.029251   0.836879   0.871429   0.792857\nauc                      0.874299 0.027893   0.851602   0.907378   0.841389\nerr                      0.169767 0.029251   0.163121   0.128571   0.207143\nerr_count               23.800000 4.086563  23.000000  18.000000  29.000000\nf0point5                 0.763671 0.029804   0.733083   0.810277   0.743034\nf1                       0.789989 0.020935   0.772277   0.820000   0.768000\nf2                       0.818491 0.014345   0.815900   0.829959   0.794702\nlift_top_group           2.664176 0.313517   3.065218   2.857143   2.372881\nlogloss                  0.432077 0.031004   0.432689   0.391192   0.478483\nmax_per_class_error      0.187373 0.027715   0.168421   0.163265   0.222222\nmcc                      0.650161 0.049185   0.653039   0.720411   0.584946\nmean_per_class_accuracy  0.831079 0.025358   0.839703   0.863422   0.795669\nmean_per_class_error     0.168921 0.025358   0.160297   0.136578   0.204331\nmse                      0.135078 0.011345   0.135005   0.120964   0.152672\npr_auc                   0.834787 0.042016   0.773003   0.882346   0.814953\nprecision                0.747210 0.035625   0.709091   0.803922   0.727273\nr2                       0.422426 0.041388   0.385804   0.468290   0.373851\nrecall                   0.838855 0.015019   0.847826   0.836735   0.813559\nrmse                     0.367275 0.015319   0.367430   0.347799   0.390732\nspecificity              0.823302 0.044511   0.831579   0.890110   0.777778\n                        cv_4_valid cv_5_valid\naccuracy                  0.814286   0.835714\nauc                       0.876458   0.894668\nerr                       0.185714   0.164286\nerr_count                26.000000  23.000000\nf0point5                  0.768072   0.763889\nf1                        0.796875   0.792793\nf2                        0.827922   0.823970\nlift_top_group            2.333333   2.692308\nlogloss                   0.429635   0.428385\nmax_per_class_error       0.212500   0.170455\nmcc                       0.631219   0.661193\nmean_per_class_accuracy   0.818750   0.837850\nmean_per_class_error      0.181250   0.162150\nmse                       0.133763   0.132989\npr_auc                    0.849705   0.853930\nprecision                 0.750000   0.745763\nr2                        0.453803   0.430380\nrecall                    0.850000   0.846154\nrmse                      0.365736   0.364676\nspecificity               0.787500   0.829545\n\n\n\n# Importancia de las variables\nh2o.varimp(aml@leader)\n\nVariable Importances: \n      variable relative_importance scaled_importance percentage\n1        Title          940.399963          1.000000   0.283786\n2          Sex          586.606567          0.623784   0.177021\n3         Fare          567.343628          0.603300   0.171208\n4          Age          460.132050          0.489294   0.138855\n5       Pclass          328.859924          0.349702   0.099241\n6  Family_size          121.330360          0.129020   0.036614\n7        SibSp           91.768562          0.097585   0.027693\n8  Family_type           87.194229          0.092720   0.026313\n9     Embarked           85.729736          0.091163   0.025871\n10       Parch           44.400452          0.047214   0.013399\n\nh2o.varimp_plot(aml@leader)\n\n\n\n\n\n# √Årea bajo la curva AUC para los datos de entrenamiento\nh2o.auc(aml@leader, train = TRUE)\n\n[1] 0.8463313\n\nh2o.performance(model = aml@leader, train = TRUE)\n\nH2OBinomialMetrics: drf\n** Reported on training data. **\n** Metrics reported on Out-Of-Bag training samples **\n\nMSE:  0.1491174\nRMSE:  0.3861573\nLogLoss:  0.5119568\nMean Per-Class Error:  0.2038026\nAUC:  0.8463313\nAUCPR:  0.8090878\nGini:  0.6926627\nR^2:  0.3667232\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         0   1    Error      Rate\n0      346  89 0.204598   =89/435\n1       54 212 0.203008   =54/266\nTotals 400 301 0.203994  =143/701\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.437500   0.747795 179\n2                       max f2  0.378927   0.795292 202\n3                 max f0point5  0.755055   0.782353  73\n4                 max accuracy  0.651129   0.803138 103\n5                max precision  0.879121   0.963855  37\n6                   max recall  0.026050   1.000000 393\n7              max specificity  1.000000   0.997701   0\n8             max absolute_mcc  0.459596   0.585658 169\n9   max min_per_class_accuracy  0.437500   0.795402 179\n10 max mean_per_class_accuracy  0.459596   0.796413 169\n11                     max tns  1.000000 434.000000   0\n12                     max fns  1.000000 250.000000   0\n13                     max fps  0.000000 435.000000 399\n14                     max tps  0.026050 266.000000 393\n15                     max tnr  1.000000   0.997701   0\n16                     max fnr  1.000000   0.939850   0\n17                     max fpr  0.000000   1.000000 399\n18                     max tpr  0.026050   1.000000 393\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n\n\n\n# Performance para datos de validaci√≥n\nh2o.auc(aml@leader, xval = TRUE)\n\n[1] 0.8709619\n\n\nRevisemos la curva entre Recall vs Precision.\nEstos 2 indicadores son de gran relevancia en la evaluaci√≥n del desempe√±o de machine learninig. La Precisi√≥n (tambi√©n llamada valor predictivo positivo) es la fracci√≥n de instancias relevantes entre las instancias recuperadas, mientras que el Recall (tambi√©n conocida como sensibilidad) es la fracci√≥n de instancias relevantes que se recuperaron.\n\n\n\n\n\nPuedes profundizar un poco m√°s sobre este tema en este art√≠culo.\n\nperf <- h2o.performance(model = aml@leader, xval = TRUE)\n\nmetrics <- as.data.frame(h2o.metric(perf))\n\nmetrics |>\n  ggplot(aes(recall, precision)) +\n  geom_line() +\n  theme_minimal()\n\n\n\n\n\n# Predicciones para test\npredictions <- h2o.predict(object = aml@leader, newdata = titanic_test_h2o)\npredictions\n\n  predict         p0        p1\n1       1 0.33766234 0.6623377\n2       1 0.07670676 0.9232932\n3       1 0.16081239 0.8391876\n4       0 0.62626263 0.3737374\n5       0 0.76809858 0.2319014\n6       1 0.21647427 0.7835257\n\n[190 rows x 3 columns] \n\n\nPara guardar el modelo generado en el directorio actual de tu computador y usarlo despu√©s, puedes usar este c√≥digo:\n\nh2o.saveModel(object = aml@leader, path = getwd(), force = TRUE)\n\n\n# Separamos dataset en test\ntitanic_test <- all_data |>\n  filter(id == \"test\") |>\n  select(-c(id, Survived, PassengerId, Name, Ticket, Cabin))\n\n# Creamos el objeto H2O\ntitanic_test_h2o <- as.h2o(titanic_test)\n\n\n# Predicciones en nuevo set de datos.\npredictions_test <- h2o.predict(object = aml@leader, newdata = titanic_test_h2o)\n\n# Separamos solo las predicciones.\nsurvived <- as.data.frame(predictions_test$predict)\n\nYa que tenemos nuestas predicciones realizadas, generaremos el archivo para luego subir a Kaggle.\n\nsubmission <- read_csv(\"gender_submission.csv\") |>\n  select(1)\n\ngender_submission <- as.data.frame(cbind(submission, survived)) |>\n  rename(\"Survived\" = predict)\n\nwrite.csv(gender_submission, \"submission_autoML_leader_h2o.csv\", row.names = FALSE)\n\n\n# Se apaga el cluster H2O\nh2o.shutdown(prompt = FALSE)"
  },
  {
    "objectID": "posts/prediccion-titanic/index.html#subir-a-kaggle",
    "href": "posts/prediccion-titanic/index.html#subir-a-kaggle",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "Subir a Kaggle",
    "text": "Subir a Kaggle\nSubimos nuestro archivo a Kaggle y btenemos una puntuaci√≥n de 0.76076\nNo esta mal, pero podr√≠a ser mejor. Hace unos meses obtuve 0.79 usando un modelo de ML ensamblado GLM + GBM (Gradient Boosting Machine).\nEn este caso, para mejorar el desempe√±o del algoritmo que fue el seleccionado como l√≠der de la comparaci√≥n de autoML, habr√≠a que tocar los hiperpar√°metros y reanalizar el feature engineering. Adem√°s, de ver opciones de otros modelos de machine learning. Pero considerar que el modelo que usamos para este art√≠culo lo realizamos aplicando autoML. Es decir, usamos modelos pre-entrenados y con auto ajustes de hiperpar√°metros ‚Äúout of the box‚Äù (predefinidos)."
  },
  {
    "objectID": "posts/prediccion-titanic/index.html#conclusiones",
    "href": "posts/prediccion-titanic/index.html#conclusiones",
    "title": "¬øQui√©n sobrevivi√≥ al accidente del Titanic?",
    "section": "Conclusiones",
    "text": "Conclusiones\nEste art√≠culo tiene fines demostrativos, no lo olvides. En la vida real, todo este proceso es (mucho) m√°s largo y complejo. Existen muchas instancias de an√°lisis estad√≠sticos y matem√©ticos sobre los datos dsponibles. Adem√°s, es un proceso iterativo. O sea, generalmente se vuelve a etapas previas frecuentemente, se revisa lo que hay. Incluso, muchas veces es necesario investigar sobre la generaci√≥n y captura de los datos. Del mismo modo, se generan muchos modelos y se realizan muchas pruebas hasta encontrar los de mejor desempe√±o y que tengan m√°s explicabilidad (seg√∫n sea el caso).\nRevisamos, adem√°s, el uso de una tecnolog√≠a emergente que son los modelos de machine learning pre-entrenados o autoML. Este tipo de modelos est√°n cada vez m√°s difundidos, en especial, en ambientes cloud. Por ejemplo, Google y Microsoft Azure tienen los suyos.\nEl desarrollo de modelos de machine learning tradicional consume bastantes recursos, y que requieren un conocimiento del dominio y tiempo significativos para generar y comparar docenas de modelos. El autoML reduce el tiempo necesario para obtener modelos de aprendizaje autom√°tico listos para producci√≥n con gran eficiencia y facilidad. Estos elementos son vitales en la actualidad para muchas startups e industrias. Adem√°s, amplia las opciones en el uso de este tipo de tecnolog√≠as a m√°s personas y organizaciones.\nA pesar de que parece magia todo √©sto (o una caja negra que nadie sabe lo que pasa dentro), el uso de autoML ayuda a generar modelos de forma m√°s r√°pida y facilita el desarrollo de modelos m√°s completos en el corto plazo. Es una buena estrategia para screening.\nOk. Entonces no necesitamos ingenieros, matem√°ticos o cient√≠ficos de datos?\nNo, para nada. Ciertamente estas tecnolog√≠as (autoML) democratizan el acceso a m√°s personas, pero a√∫n son necesarios los conocimientos y reflexiones de los expertos en el √°rea para ajustar los modelos, controlar sesgos o problemas de equidad. Y, por cierto, que conozcan del negocio, pues finalmente el desarrollo de estas tecnolog√≠as buscan resolver problem√°ticas concretas. Sin mencionar todo el trabajo de comunicaci√≥n, explicaci√≥n y disfusi√≥n de los resultados, para los cual esos perfiles profesionales son de gran valor.\nFinalmente, este ejercicio que hemos visto ac√° es m√°s demostrativo que otra cosa, pero espero haberte mostrado c√≥mo se pueden entrenar algoritmos y usar modelos de ML para generar predicciones.\nNos vemos!! ü§™"
  },
  {
    "objectID": "posts/compras-publicas/index.html",
    "href": "posts/compras-publicas/index.html",
    "title": "¬øA qui√©n le compra m√°s el Estado?",
    "section": "",
    "text": "Hola!!\n¬øTe gustar√≠a aprender a usar datos abiertos de compras p√∫blicas (Chile) y realizar este lindo gr√°fico?\nPues bueno, ac√° te ense√±o paso a paso.\nAh! No voy a realizar juicios de valor sobre los resultados. El fin de este art√≠culo es mostrar una forma de usar datos abiertos y utilizando programaci√≥n, realizar un breve an√°lisis de consolidaci√≥n de los datos y realizar el gr√°fico.\nDicho eso, pero sin dejar de mencionar que llama la atenci√≥n los 3 primeros proveedores a los cuales se le ha comprado m√°s jajaja üòÇ, vamos con el tema."
  },
  {
    "objectID": "posts/compras-publicas/index.html#los-datos",
    "href": "posts/compras-publicas/index.html#los-datos",
    "title": "¬øA qui√©n le compra m√°s el Estado?",
    "section": "Los datos",
    "text": "Los datos\nEl objetivo es investigar qu√© proveedores son los m√°s top en adjudicarse √≥rdenes de compra en salud.\nPara ello, usaremos los datos abiertos disponibles en la plataforma de ChileCompra.\nEsta web es interesante, pues contiene los datos de todas las compras p√∫blicas desde hace muchos a√±os hasta la fecha, que se han realizado por medio de Mercado P√∫blico. Por fines de investigaci√≥n, siempre es una buena idea indagar en qu√© tipo de datos est√°s disponibles y cuales no. Adem√°s, de entender las distintas variables que contiene. Para eso, puedes revisar la documentaci√≥n que el mismo sitio posee.\nOk. Partamos! üòé\nCargamos las librerias de R que usaremos:\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(archive)\nlibrary(data.table)\nlibrary(lubridate)\nlibrary(hrbrthemes)\n\nVamos a utilizar la descripci√≥n que sale en la documentaci√≥n sobre el uso de URL¬¥s para la descarga de los archivos.\nExiste la posibilidad de usar una API, pero requiere de un registro previo que no tengo, por lo cual no usar√© esa opci√≥n. Sin embargo, esa ser√≠a la opci√≥n ideal para nuestro caso.\n\n\n\n\n\nBasado en el ejemplo, como deseo descargar los datos de las √≥rdenes de compra de salud habr√≠a que tener construir un link similar a https://chc-oc-files.s3.amazonaws.com/sector/2020/Sem1/Salud.7z\nConstruyamos un peque√±o loop para generar las URL¬¥s necesarias para la descarga de los datos.\nEn la plataforma hay registros para los a√±os 2007 al 2022, separados por semestres en cada caso. Pero para efectos de este art√≠culo solo descargar√© desde el a√±o 2017 en adelante.\n\ntotal_url <- list()\n\nyear <- as.character(2017:2022)\n\nfor (i in year) {\n  url_sem1 <- paste0(\"https://chc-oc-files.s3.amazonaws.com/sector/\", i, \"/Sem1/Salud.7z\")\n  url_sem2 <- paste0(\"https://chc-oc-files.s3.amazonaws.com/sector/\", i, \"/Sem2/Salud.7z\")\n\n  total_url[[i]] <- c(url_sem1, url_sem2)\n}\n\nVeamos las URL¬¥s:\n\nurls <- unlist(total_url, use.names = FALSE)\nurls\n\n [1] \"https://chc-oc-files.s3.amazonaws.com/sector/2017/Sem1/Salud.7z\"\n [2] \"https://chc-oc-files.s3.amazonaws.com/sector/2017/Sem2/Salud.7z\"\n [3] \"https://chc-oc-files.s3.amazonaws.com/sector/2018/Sem1/Salud.7z\"\n [4] \"https://chc-oc-files.s3.amazonaws.com/sector/2018/Sem2/Salud.7z\"\n [5] \"https://chc-oc-files.s3.amazonaws.com/sector/2019/Sem1/Salud.7z\"\n [6] \"https://chc-oc-files.s3.amazonaws.com/sector/2019/Sem2/Salud.7z\"\n [7] \"https://chc-oc-files.s3.amazonaws.com/sector/2020/Sem1/Salud.7z\"\n [8] \"https://chc-oc-files.s3.amazonaws.com/sector/2020/Sem2/Salud.7z\"\n [9] \"https://chc-oc-files.s3.amazonaws.com/sector/2021/Sem1/Salud.7z\"\n[10] \"https://chc-oc-files.s3.amazonaws.com/sector/2021/Sem2/Salud.7z\"\n[11] \"https://chc-oc-files.s3.amazonaws.com/sector/2022/Sem1/Salud.7z\"\n[12] \"https://chc-oc-files.s3.amazonaws.com/sector/2022/Sem2/Salud.7z\"\n\n\nMuy bien!! Nos qued√≥ genial!\nAhora nos toca descargar los archivos desde esas direcciones web.\n\nfor (i in 1:length(urls)) {\n  destfile <- paste0(here::here(), \"/data/\", i, \".7z\")\n  url <- urls[i]\n  download.file(url, destfile, mode = \"wb\")\n}\n\nLos archivos tambi√©n pueden descargarse desde la misma plataforma sin necesidad de usar estas URL¬¥s, sino que por medio de la propia interfaz de Mercado P√∫blico. Sin embargo, me parece mejor idea el usar c√≥digo para automatizar esas tareas para as√≠ evitar errores manuales y facilitar la descarga de nuevos archivos en un futuro.\nF√≠jate que los archivos vienen comprimidos en un formato 7z.\nSi abrimos un archivo, nos encontraremos con otros 3 √≥ 4 en su interior:\n\nConvenio marco\nLicitaciones\nTrato directo\nCompra √°gil\n\nEn mi caso, me interesa indagar en los tratos directos.\n¬øEl motivo?\nMe parecen m√°s interesantes esos datos, puesto que hay gran variedad de compras y es en esta modalidad de compra en donde, muchas veces, se presta para fraude o problemas de legitimidad. Aunque con este art√≠culo no pretendo realizar un an√°lisis de ese estilo, podr√≠a ser de inter√©s para alguien m√°s y ocuparlo como base para fines de investigaci√≥n.\nA continuaci√≥n realizar√© algunos loops para automatizar la extracci√≥n de los datos.\nCabe mencionar que se podr√≠a hacer en menos lineas de c√≥digo, pero prefiero dejarlo as√≠ para que te sea m√°s simple de seguir el paso a paso.\nPara la funci√≥n de extracci√≥n (descomprimir) de m√°s abajo, necesitamos ponerle nombres de los archivos 7z para pas√°rselo a la funci√≥n archive_extract().\n\nfiles_zipped <- list()\n\nfor (i in 1:length(urls)) {\n  file_name_zip <- paste0(\"data/\", i, \".7z\")\n  files_zipped[[i]] <- file_name_zip\n}\n\nfiles_zipped <- unlist(files_zipped, use.names = FALSE)\n\nfiles_zipped\n\n [1] \"data/1.7z\"  \"data/2.7z\"  \"data/3.7z\"  \"data/4.7z\"  \"data/5.7z\" \n [6] \"data/6.7z\"  \"data/7.7z\"  \"data/8.7z\"  \"data/9.7z\"  \"data/10.7z\"\n[11] \"data/11.7z\" \"data/12.7z\"\n\n\nLos archivos de los ultimos 2 a√±os son diferentes a los anteriores y el nombre del archivo comprimido es distinto. Para resolver eso, implement√© un if(), seg√∫n qu√© archivo sea.\n\nhere::i_am(\"index.qmd\")\n\noc <- list()\n\nfor (i in files_zipped) {\n  archive_extract(archive = i, dir = \"data\")\n\n  if (file.exists(\"data/17TratoDirecto.csv\")) {\n    oc[[i]] <- fread(\"data/17TratoDirecto.csv\", encoding = \"Latin-1\")\n  } else {\n    oc[[i]] <- fread(\"data/17OCTratoDirecto.csv\", encoding = \"Latin-1\")\n  }\n}\n\nAhora pasamos el objeto que nos hab√≠amos creado a un data.frame y lo ‚Äúaplanamos‚Äù para no tener problemas despu√©s con los an√°lisis. Para lo √∫ltimo, usamos unnest().\n\nall_data <- rbindlist(oc) |> \n  unnest(cols = c())\n\nVeamos todas las variables que contiene el archivo.\n\ndim(all_data) #Filas y Columnas\n\n[1] 1429423      44\n\n\n\nnames(all_data) #Nombre de variables\n\n [1] \"codigoOC\"               \"FechaEnvioOC\"           \"NombreOC\"              \n [4] \"DescripcionOC\"          \"EstadoOC\"               \"ProcedenciaOC\"         \n [7] \"MonedaOC\"               \"MontoNetoOC\"            \"DescuentosOC\"          \n[10] \"CargosOC\"               \"ImpuestosOC\"            \"MontoTotalOC\"          \n[13] \"ImpuestosOC_CLP\"        \"MontoNetoOC_CLP\"        \"MetodoPago\"            \n[16] \"TipoDespacho\"           \"Financiamiento\"         \"UnidadCompra\"          \n[19] \"UnidadCompraRUT\"        \"RegionUnidadCompra\"     \"entCode\"               \n[22] \"Institucion\"            \"Sector\"                 \"Proveedor\"             \n[25] \"ProveedorRUT\"           \"ActividadProveedor\"     \"TamanoProveedor\"       \n[28] \"RegionProveedor\"        \"RubroN1\"                \"RubroN2\"               \n[31] \"RubroN3\"                \"CodigoProductoONU\"      \"ONUProducto\"           \n[34] \"NombreItem\"             \"DescripcionItem\"        \"CantidadItem\"          \n[37] \"UnidadMedida\"           \"MonedaItem\"             \"MontoNetoItem\"         \n[40] \"DescuentoItem\"          \"CargosItem\"             \"ImpuestoEspecificoItem\"\n[43] \"MontoTotalItem\"         \"MontoNetoItemCLP\"      \n\n\nImportante\nLos archivos descargados son grandes y cuando se descrompimen, los son mucho m√°s! Algunos llegan a pesar m√°s de 200 o 300 Mb. De hecho, el objeto con todos los datos combinados sobrepasa 1 GB y tiene casi 1 mill√≥n y medio de filas. Con un Excel no podr√°s abrirlo, pues supera su l√≠mite. Por eso es importante usar programaci√≥n. Otra instancia ser√≠a levantar un servidor SQL y cargar los datos, pero me parece que no vale la pena paa estos efectos.\nComo los archivos descargados son bastante grandes, es mejor borrarlos, pues ya tenemos lo que necesitamos.\n\nunlink(here::here(\"data/*\"), recursive = TRUE, force = TRUE)"
  },
  {
    "objectID": "posts/compras-publicas/index.html#an√°lisis",
    "href": "posts/compras-publicas/index.html#an√°lisis",
    "title": "¬øA qui√©n le compra m√°s el Estado?",
    "section": "An√°lisis",
    "text": "An√°lisis\nVoy a considerar s√≥lo las √≥rdenes de compra (OC) en estados de recepci√≥n conforme y aceptadas. Esta es una decisi√≥n que tom√© en base a lo que se menciona en el portal, en especial, a los est√°ndares OCDS.\nEstos est√°ndares permiten tener un lenguaje com√∫n sobre el estado de las OC y un formato estructurado que facilite la revisi√≥n, comprensi√≥n y consumo de los datos.\nLa decisi√≥n de usar solo esas etapas es m√°s que nada para sacar del an√°lisis todas aquellas OC que fueron rechazadas, tienen observaciones o sufrieron modificaciones en el camino. La idea es dejar aquellas efectivamente ejecutadas o que si bien a√∫n no ocurren, ya fueron aceptadas por las partes.\n\n\n\n\n\nAlgo que me parece interesante de observar, es el gasto asociado a esas OC durante los a√±os analizados.\n\nsuppliers <- all_data |>\n  filter(EstadoOC %in% c(\"Recepcion Conforme\", \"Aceptada\")) |>\n  separate(FechaEnvioOC, into = c(\"Fecha\", \"Hora\"), sep = \" \", remove = TRUE) |>\n  mutate(Fecha = dmy(Fecha)) |>\n  group_by(Proveedor, year = year(Fecha)) |>\n  summarise(mount = sum(as.numeric(MontoTotalItem), na.rm = TRUE)) |>\n  ungroup()\n\n\nsuppliers |>\n  group_by(year) |>\n  summarise(mount = sum(mount, na.rm = TRUE)) |>\n  ggplot(aes(year, mount)) +\n  geom_col() +\n  scale_y_continuous(labels = scales::comma) +\n  scale_x_continuous(breaks = c(2017, 2018, 2019, 2020, 2021, 2022)) +\n  theme_bw() +\n  labs(\n    x = \"A√±o\",\n    y = \"Monto Total OC ($)\"\n  )\n\n\n\n\nVemos que en los a√±os 2022 y 2021 los montos asociados a este tipo de OC aumentario de forma considerable respecto de los a√±os anteriores. Posiblemente, eso tenga mucha relaci√≥n con la pandemia y la necesidad de contar r√°pidamente con insumos, medicamentos, infraestructura, personal, ex√°menes y muchas otras cosas.\nSi vemos los proveedores, podemos hace un r√°nking de √©stos y revisar cu√°les fueron los 5 de cada a√±o que tuvieron mayores cantidades de transacciones por OC:\n\ntop5_by_year <- suppliers |>\n  mutate(Proveedor = str_to_upper(Proveedor)) |>\n  arrange(desc(mount)) |>\n  group_by(year) |>\n  do(head(., 5)) |>\n  ungroup()\n\ntop5_by_year |>\n  DT::datatable()\n\n\n\n\n\n\nSi tienes inter√©s en profundizar en el tema, ya tienes todo lo necesario. Tienes los datos y el c√≥digo para replicarlo. Puedes seguir investigando los registros, de seguro hay cosas entretenidas. Quiz√°s quieras dirigir el an√°lisis a un proveedor en espec√≠fico o a una instituci√≥n p√∫blica en especial. La verdad, no hay l√≠mites. Solo tu curiosidad e imaginaci√≥n."
  },
  {
    "objectID": "posts/compras-publicas/index.html#gr√°fico",
    "href": "posts/compras-publicas/index.html#gr√°fico",
    "title": "¬øA qui√©n le compra m√°s el Estado?",
    "section": "Gr√°fico",
    "text": "Gr√°fico\nPodemos graficarlo para ver mejor esos datos y analizar el comportamiento a lo largo de los a√±os de los proveedores con m√°s montos en OC.\nPara eso usaremos la famosa libreria ggplot2 con algunos agregados para hacer el gr√°fico m√°s atractivo.\n\nplot <- top5_by_year |>\n  mutate(Proveedor = fct_reorder(Proveedor, mount, .fun = \"sum\"),\n         mount_mill = mount/1e6) |> \n  ggplot(aes(Proveedor, mount_mill, fill = factor(year))) +\n  geom_col(position = \"stack\") +\n  coord_flip() +\n  scale_y_continuous(labels = scales::comma) +\n  expand_limits( y = c(0, 250000)) +\n  labs(title = \"Compras p√∫blicas por trato directo en el sector salud\",\n       subtitle = \"Se consideran las OC con estados de recepci√≥n conforme y aceptadas\",\n       x = \"\",\n       y = \"Millones de pesos ($)\",\n       fill = \"A√±o\",\n       caption = \"Fuente: ChileCompra (https://datos-abiertos.chilecompra.cl)\\nElaborado por Paulo Villarroel\") +\n  theme_ipsum_rc(grid = \"XY\") +\n  theme(axis.text.x = element_text(hjust = c(0, 0.5, 0.5, 0.5, 1)))\n\n\n\n\n\n\nSi quieres ver la imagen m√°s grande, dale al boton derecho y abrir en nueva ventena.\nSi, Si. Es el mismo gr√°fico del inicio ü•∞\nListo!!"
  },
  {
    "objectID": "posts/compras-publicas/index.html#finalmente",
    "href": "posts/compras-publicas/index.html#finalmente",
    "title": "¬øA qui√©n le compra m√°s el Estado?",
    "section": "Finalmente",
    "text": "Finalmente\nEspero que te haya gustado este art√≠culo. Trat√© de ser lo m√°s explicativo posible. Adem√°s, de dejarte el paso a paso para que tu sigas adelante.\nLos datos abiertos son una muy buena oportunidad para que la ciudadan√≠a pueda realizar fiscalizaci√≥n y auditoria al funcionamiento de los organismos p√∫blicos. Eso si, se requiere de ciertos conocimientos para saber d√≥nde encontrar esos datos y para poder analizarlos. Es mi deseo que este art√≠culo te sea de ayuda, despierte tu curiosidad y seamos agentes de divulgaci√≥n cient√≠fica de cara a la gente.\nNos vemos!!"
  }
]